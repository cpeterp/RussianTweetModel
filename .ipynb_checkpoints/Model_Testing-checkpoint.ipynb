{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package stopwords to\n",
      "[nltk_data]     C:\\Users\\599701\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import scipy as sp\n",
    "\n",
    "from pprint import pprint\n",
    "from time import time\n",
    "from textblob import TextBlob, Word\n",
    "\n",
    "import logging\n",
    "from nltk.stem.snowball import SnowballStemmer\n",
    "from nltk.corpus import stopwords\n",
    "import nltk\n",
    "nltk.download('stopwords')\n",
    "\n",
    "from sklearn.model_selection import train_test_split as tts\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "from sklearn.naive_bayes import MultinomialNB         # Naive Bayes\n",
    "from sklearn import metrics\n",
    "\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.pipeline import Pipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "tweet_data = pd.read_csv(\"./datasets/combined_data.csv\", sep=\";\", \n",
    "                         dtype={'tweet_id':str, 'author_id':str, 'publish_date':str, \n",
    "                                'content':str, 'link_url':str, 'account_category':str, \n",
    "                                'author':str, 'account_type':str})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "tweet_data = pd.get_dummies(tweet_data, columns=['account_category'], drop_first=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_Troll = tweet_data[tweet_data.account_category_Troll == 1]\n",
    "df_Pol = tweet_data[tweet_data.account_category_Politician == 1]\n",
    "df_News = tweet_data[tweet_data.account_category_US_News == 1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(41069, 12)\n",
      "(41066, 12)\n",
      "(41069, 12)\n"
     ]
    }
   ],
   "source": [
    "print(df_Troll.shape)\n",
    "print(df_Pol.shape)\n",
    "print(df_News.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Some different testing sets\n",
    "df_Trolls_News = pd.concat([df_Troll, df_News])\n",
    "df_Trolls_Pol = pd.concat([df_Troll, df_Pol])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We'll start by comparing trolls and news outlets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = df_Trolls_News['content']\n",
    "y = df_Trolls_News['account_category_Troll']\n",
    "X_train, X_test, y_train, y_test = tts(X, y, random_state=42)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Define functions to stem or lemmatze text in a tweet. Also create the list of stop words to use with them."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define a function that accepts text and returns a list of stems.\n",
    "stemmer = SnowballStemmer('english')\n",
    "def split_into_stems(text):\n",
    "    text = str(text).lower()\n",
    "    words = TextBlob(text).words\n",
    "    return [stemmer.stem(word) for word in words]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "stemmed_stops = [stemmer.stem(Word(x)) for x in stopwords.words('english')]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define a function that accepts text and returns a list of lemmas.\n",
    "def split_into_lemmas(text):\n",
    "    text = str(text).lower()\n",
    "    words = TextBlob(text).words\n",
    "    return [word.lemmatize() for word in words]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "lemmed_stops = [Word(x).lemmatize() for x in stopwords.words('english')]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now I need to define the pipline and gridsearch parameters."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "pipeline = Pipeline([\n",
    "    ('vect', CountVectorizer()),\n",
    "    ('clf', MultinomialNB())])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "parameters = {\n",
    "    'vect__analyzer': (split_into_lemmas, split_into_stems),\n",
    "    'vect__max_df': (0.75, 1.0),\n",
    "    'vect__min_df': (1, 2, 3),\n",
    "    #'vect__max_features': (None, 5000, 10000, 50000),\n",
    "    'vect__ngram_range': ((1, 1), (1, 2))  # unigrams or bigrams\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 3 folds for each of 24 candidates, totalling 72 fits\n",
      "[CV] vect__analyzer=<function split_into_lemmas at 0x000002077A15F7B8>, vect__max_df=0.75, vect__min_df=1, vect__ngram_range=(1, 1) \n",
      "[CV]  vect__analyzer=<function split_into_lemmas at 0x000002077A15F7B8>, vect__max_df=0.75, vect__min_df=1, vect__ngram_range=(1, 1), score=0.8319941563184806, total=  36.4s\n",
      "[CV] vect__analyzer=<function split_into_lemmas at 0x000002077A15F7B8>, vect__max_df=0.75, vect__min_df=1, vect__ngram_range=(1, 1) \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:  1.0min remaining:    0.0s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV]  vect__analyzer=<function split_into_lemmas at 0x000002077A15F7B8>, vect__max_df=0.75, vect__min_df=1, vect__ngram_range=(1, 1), score=0.8322294730690561, total=  37.9s\n",
      "[CV] vect__analyzer=<function split_into_lemmas at 0x000002077A15F7B8>, vect__max_df=0.75, vect__min_df=1, vect__ngram_range=(1, 1) \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Done   2 out of   2 | elapsed:  2.1min remaining:    0.0s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV]  vect__analyzer=<function split_into_lemmas at 0x000002077A15F7B8>, vect__max_df=0.75, vect__min_df=1, vect__ngram_range=(1, 1), score=0.8259472095061848, total=  37.1s\n",
      "[CV] vect__analyzer=<function split_into_lemmas at 0x000002077A15F7B8>, vect__max_df=0.75, vect__min_df=1, vect__ngram_range=(1, 2) \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Done   3 out of   3 | elapsed:  3.1min remaining:    0.0s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV]  vect__analyzer=<function split_into_lemmas at 0x000002077A15F7B8>, vect__max_df=0.75, vect__min_df=1, vect__ngram_range=(1, 2), score=0.8319941563184806, total=  37.2s\n",
      "[CV] vect__analyzer=<function split_into_lemmas at 0x000002077A15F7B8>, vect__max_df=0.75, vect__min_df=1, vect__ngram_range=(1, 2) \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Done   4 out of   4 | elapsed:  4.1min remaining:    0.0s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV]  vect__analyzer=<function split_into_lemmas at 0x000002077A15F7B8>, vect__max_df=0.75, vect__min_df=1, vect__ngram_range=(1, 2), score=0.8322294730690561, total=  37.6s\n",
      "[CV] vect__analyzer=<function split_into_lemmas at 0x000002077A15F7B8>, vect__max_df=0.75, vect__min_df=1, vect__ngram_range=(1, 2) \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Done   5 out of   5 | elapsed:  5.2min remaining:    0.0s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV]  vect__analyzer=<function split_into_lemmas at 0x000002077A15F7B8>, vect__max_df=0.75, vect__min_df=1, vect__ngram_range=(1, 2), score=0.8259472095061848, total=  58.1s\n",
      "[CV] vect__analyzer=<function split_into_lemmas at 0x000002077A15F7B8>, vect__max_df=0.75, vect__min_df=2, vect__ngram_range=(1, 1) \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Done   6 out of   6 | elapsed:  6.6min remaining:    0.0s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV]  vect__analyzer=<function split_into_lemmas at 0x000002077A15F7B8>, vect__max_df=0.75, vect__min_df=2, vect__ngram_range=(1, 1), score=0.8287314341368396, total=  42.6s\n",
      "[CV] vect__analyzer=<function split_into_lemmas at 0x000002077A15F7B8>, vect__max_df=0.75, vect__min_df=2, vect__ngram_range=(1, 1) \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Done   7 out of   7 | elapsed:  7.8min remaining:    0.0s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV]  vect__analyzer=<function split_into_lemmas at 0x000002077A15F7B8>, vect__max_df=0.75, vect__min_df=2, vect__ngram_range=(1, 1), score=0.827943897925392, total=  39.9s\n",
      "[CV] vect__analyzer=<function split_into_lemmas at 0x000002077A15F7B8>, vect__max_df=0.75, vect__min_df=2, vect__ngram_range=(1, 1) \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Done   8 out of   8 | elapsed:  8.9min remaining:    0.0s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV]  vect__analyzer=<function split_into_lemmas at 0x000002077A15F7B8>, vect__max_df=0.75, vect__min_df=2, vect__ngram_range=(1, 1), score=0.821759033797604, total=  44.0s\n",
      "[CV] vect__analyzer=<function split_into_lemmas at 0x000002077A15F7B8>, vect__max_df=0.75, vect__min_df=2, vect__ngram_range=(1, 2) \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Done   9 out of   9 | elapsed: 10.1min remaining:    0.0s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV]  vect__analyzer=<function split_into_lemmas at 0x000002077A15F7B8>, vect__max_df=0.75, vect__min_df=2, vect__ngram_range=(1, 2), score=0.8287314341368396, total=  46.3s\n",
      "[CV] vect__analyzer=<function split_into_lemmas at 0x000002077A15F7B8>, vect__max_df=0.75, vect__min_df=2, vect__ngram_range=(1, 2) \n",
      "[CV]  vect__analyzer=<function split_into_lemmas at 0x000002077A15F7B8>, vect__max_df=0.75, vect__min_df=2, vect__ngram_range=(1, 2), score=0.827943897925392, total=  44.3s\n",
      "[CV] vect__analyzer=<function split_into_lemmas at 0x000002077A15F7B8>, vect__max_df=0.75, vect__min_df=2, vect__ngram_range=(1, 2) \n",
      "[CV]  vect__analyzer=<function split_into_lemmas at 0x000002077A15F7B8>, vect__max_df=0.75, vect__min_df=2, vect__ngram_range=(1, 2), score=0.821759033797604, total=  36.6s\n",
      "[CV] vect__analyzer=<function split_into_lemmas at 0x000002077A15F7B8>, vect__max_df=0.75, vect__min_df=3, vect__ngram_range=(1, 1) \n",
      "[CV]  vect__analyzer=<function split_into_lemmas at 0x000002077A15F7B8>, vect__max_df=0.75, vect__min_df=3, vect__ngram_range=(1, 1), score=0.8230338446554663, total=  45.7s\n",
      "[CV] vect__analyzer=<function split_into_lemmas at 0x000002077A15F7B8>, vect__max_df=0.75, vect__min_df=3, vect__ngram_range=(1, 1) \n",
      "[CV]  vect__analyzer=<function split_into_lemmas at 0x000002077A15F7B8>, vect__max_df=0.75, vect__min_df=3, vect__ngram_range=(1, 1), score=0.824583617415019, total=  39.1s\n",
      "[CV] vect__analyzer=<function split_into_lemmas at 0x000002077A15F7B8>, vect__max_df=0.75, vect__min_df=3, vect__ngram_range=(1, 1) \n",
      "[CV]  vect__analyzer=<function split_into_lemmas at 0x000002077A15F7B8>, vect__max_df=0.75, vect__min_df=3, vect__ngram_range=(1, 1), score=0.8180578552644394, total=  49.4s\n",
      "[CV] vect__analyzer=<function split_into_lemmas at 0x000002077A15F7B8>, vect__max_df=0.75, vect__min_df=3, vect__ngram_range=(1, 2) \n",
      "[CV]  vect__analyzer=<function split_into_lemmas at 0x000002077A15F7B8>, vect__max_df=0.75, vect__min_df=3, vect__ngram_range=(1, 2), score=0.8230338446554663, total=  48.9s\n",
      "[CV] vect__analyzer=<function split_into_lemmas at 0x000002077A15F7B8>, vect__max_df=0.75, vect__min_df=3, vect__ngram_range=(1, 2) \n",
      "[CV]  vect__analyzer=<function split_into_lemmas at 0x000002077A15F7B8>, vect__max_df=0.75, vect__min_df=3, vect__ngram_range=(1, 2), score=0.824583617415019, total=  50.0s\n",
      "[CV] vect__analyzer=<function split_into_lemmas at 0x000002077A15F7B8>, vect__max_df=0.75, vect__min_df=3, vect__ngram_range=(1, 2) \n",
      "[CV]  vect__analyzer=<function split_into_lemmas at 0x000002077A15F7B8>, vect__max_df=0.75, vect__min_df=3, vect__ngram_range=(1, 2), score=0.8180578552644394, total=  35.1s\n",
      "[CV] vect__analyzer=<function split_into_lemmas at 0x000002077A15F7B8>, vect__max_df=1.0, vect__min_df=1, vect__ngram_range=(1, 1) \n",
      "[CV]  vect__analyzer=<function split_into_lemmas at 0x000002077A15F7B8>, vect__max_df=1.0, vect__min_df=1, vect__ngram_range=(1, 1), score=0.8309715120525931, total=  35.8s\n",
      "[CV] vect__analyzer=<function split_into_lemmas at 0x000002077A15F7B8>, vect__max_df=1.0, vect__min_df=1, vect__ngram_range=(1, 1) \n",
      "[CV]  vect__analyzer=<function split_into_lemmas at 0x000002077A15F7B8>, vect__max_df=1.0, vect__min_df=1, vect__ngram_range=(1, 1), score=0.8334956657251388, total=  43.1s\n",
      "[CV] vect__analyzer=<function split_into_lemmas at 0x000002077A15F7B8>, vect__max_df=1.0, vect__min_df=1, vect__ngram_range=(1, 1) \n",
      "[CV]  vect__analyzer=<function split_into_lemmas at 0x000002077A15F7B8>, vect__max_df=1.0, vect__min_df=1, vect__ngram_range=(1, 1), score=0.8255576117658517, total=  40.8s\n",
      "[CV] vect__analyzer=<function split_into_lemmas at 0x000002077A15F7B8>, vect__max_df=1.0, vect__min_df=1, vect__ngram_range=(1, 2) \n",
      "[CV]  vect__analyzer=<function split_into_lemmas at 0x000002077A15F7B8>, vect__max_df=1.0, vect__min_df=1, vect__ngram_range=(1, 2), score=0.8309715120525931, total=  37.6s\n",
      "[CV] vect__analyzer=<function split_into_lemmas at 0x000002077A15F7B8>, vect__max_df=1.0, vect__min_df=1, vect__ngram_range=(1, 2) \n",
      "[CV]  vect__analyzer=<function split_into_lemmas at 0x000002077A15F7B8>, vect__max_df=1.0, vect__min_df=1, vect__ngram_range=(1, 2), score=0.8334956657251388, total=  41.1s\n",
      "[CV] vect__analyzer=<function split_into_lemmas at 0x000002077A15F7B8>, vect__max_df=1.0, vect__min_df=1, vect__ngram_range=(1, 2) \n",
      "[CV]  vect__analyzer=<function split_into_lemmas at 0x000002077A15F7B8>, vect__max_df=1.0, vect__min_df=1, vect__ngram_range=(1, 2), score=0.8255576117658517, total=  40.2s\n",
      "[CV] vect__analyzer=<function split_into_lemmas at 0x000002077A15F7B8>, vect__max_df=1.0, vect__min_df=2, vect__ngram_range=(1, 1) \n",
      "[CV]  vect__analyzer=<function split_into_lemmas at 0x000002077A15F7B8>, vect__max_df=1.0, vect__min_df=2, vect__ngram_range=(1, 1), score=0.8287314341368396, total=  43.9s\n",
      "[CV] vect__analyzer=<function split_into_lemmas at 0x000002077A15F7B8>, vect__max_df=1.0, vect__min_df=2, vect__ngram_range=(1, 1) \n",
      "[CV]  vect__analyzer=<function split_into_lemmas at 0x000002077A15F7B8>, vect__max_df=1.0, vect__min_df=2, vect__ngram_range=(1, 1), score=0.8281873965131002, total=  41.6s\n",
      "[CV] vect__analyzer=<function split_into_lemmas at 0x000002077A15F7B8>, vect__max_df=1.0, vect__min_df=2, vect__ngram_range=(1, 1) \n",
      "[CV]  vect__analyzer=<function split_into_lemmas at 0x000002077A15F7B8>, vect__max_df=1.0, vect__min_df=2, vect__ngram_range=(1, 1), score=0.8211259374695626, total=  43.5s\n",
      "[CV] vect__analyzer=<function split_into_lemmas at 0x000002077A15F7B8>, vect__max_df=1.0, vect__min_df=2, vect__ngram_range=(1, 2) \n",
      "[CV]  vect__analyzer=<function split_into_lemmas at 0x000002077A15F7B8>, vect__max_df=1.0, vect__min_df=2, vect__ngram_range=(1, 2), score=0.8287314341368396, total=  44.2s\n",
      "[CV] vect__analyzer=<function split_into_lemmas at 0x000002077A15F7B8>, vect__max_df=1.0, vect__min_df=2, vect__ngram_range=(1, 2) \n",
      "[CV]  vect__analyzer=<function split_into_lemmas at 0x000002077A15F7B8>, vect__max_df=1.0, vect__min_df=2, vect__ngram_range=(1, 2), score=0.8281873965131002, total= 1.2min\n",
      "[CV] vect__analyzer=<function split_into_lemmas at 0x000002077A15F7B8>, vect__max_df=1.0, vect__min_df=2, vect__ngram_range=(1, 2) \n",
      "[CV]  vect__analyzer=<function split_into_lemmas at 0x000002077A15F7B8>, vect__max_df=1.0, vect__min_df=2, vect__ngram_range=(1, 2), score=0.8211259374695626, total=  58.1s\n",
      "[CV] vect__analyzer=<function split_into_lemmas at 0x000002077A15F7B8>, vect__max_df=1.0, vect__min_df=3, vect__ngram_range=(1, 1) \n",
      "[CV]  vect__analyzer=<function split_into_lemmas at 0x000002077A15F7B8>, vect__max_df=1.0, vect__min_df=3, vect__ngram_range=(1, 1), score=0.8241538836133431, total=  39.5s\n",
      "[CV] vect__analyzer=<function split_into_lemmas at 0x000002077A15F7B8>, vect__max_df=1.0, vect__min_df=3, vect__ngram_range=(1, 1) \n",
      "[CV]  vect__analyzer=<function split_into_lemmas at 0x000002077A15F7B8>, vect__max_df=1.0, vect__min_df=3, vect__ngram_range=(1, 1), score=0.8257037109184767, total=  40.0s\n",
      "[CV] vect__analyzer=<function split_into_lemmas at 0x000002077A15F7B8>, vect__max_df=1.0, vect__min_df=3, vect__ngram_range=(1, 1) \n",
      "[CV]  vect__analyzer=<function split_into_lemmas at 0x000002077A15F7B8>, vect__max_df=1.0, vect__min_df=3, vect__ngram_range=(1, 1), score=0.8183013538521476, total=  43.9s\n",
      "[CV] vect__analyzer=<function split_into_lemmas at 0x000002077A15F7B8>, vect__max_df=1.0, vect__min_df=3, vect__ngram_range=(1, 2) \n",
      "[CV]  vect__analyzer=<function split_into_lemmas at 0x000002077A15F7B8>, vect__max_df=1.0, vect__min_df=3, vect__ngram_range=(1, 2), score=0.8241538836133431, total=  43.5s\n",
      "[CV] vect__analyzer=<function split_into_lemmas at 0x000002077A15F7B8>, vect__max_df=1.0, vect__min_df=3, vect__ngram_range=(1, 2) \n",
      "[CV]  vect__analyzer=<function split_into_lemmas at 0x000002077A15F7B8>, vect__max_df=1.0, vect__min_df=3, vect__ngram_range=(1, 2), score=0.8257037109184767, total=  44.6s\n",
      "[CV] vect__analyzer=<function split_into_lemmas at 0x000002077A15F7B8>, vect__max_df=1.0, vect__min_df=3, vect__ngram_range=(1, 2) \n",
      "[CV]  vect__analyzer=<function split_into_lemmas at 0x000002077A15F7B8>, vect__max_df=1.0, vect__min_df=3, vect__ngram_range=(1, 2), score=0.8183013538521476, total=  45.0s\n",
      "[CV] vect__analyzer=<function split_into_stems at 0x000002076DC30AE8>, vect__max_df=0.75, vect__min_df=1, vect__ngram_range=(1, 1) \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV]  vect__analyzer=<function split_into_stems at 0x000002076DC30AE8>, vect__max_df=0.75, vect__min_df=1, vect__ngram_range=(1, 1), score=0.8378378378378378, total=  54.4s\n",
      "[CV] vect__analyzer=<function split_into_stems at 0x000002076DC30AE8>, vect__max_df=0.75, vect__min_df=1, vect__ngram_range=(1, 1) \n",
      "[CV]  vect__analyzer=<function split_into_stems at 0x000002076DC30AE8>, vect__max_df=0.75, vect__min_df=1, vect__ngram_range=(1, 1), score=0.8385117366319276, total=  56.1s\n",
      "[CV] vect__analyzer=<function split_into_stems at 0x000002076DC30AE8>, vect__max_df=0.75, vect__min_df=1, vect__ngram_range=(1, 1) \n",
      "[CV]  vect__analyzer=<function split_into_stems at 0x000002076DC30AE8>, vect__max_df=0.75, vect__min_df=1, vect__ngram_range=(1, 1), score=0.8311580792831401, total=  47.7s\n",
      "[CV] vect__analyzer=<function split_into_stems at 0x000002076DC30AE8>, vect__max_df=0.75, vect__min_df=1, vect__ngram_range=(1, 2) \n",
      "[CV]  vect__analyzer=<function split_into_stems at 0x000002076DC30AE8>, vect__max_df=0.75, vect__min_df=1, vect__ngram_range=(1, 2), score=0.8378378378378378, total=  42.8s\n",
      "[CV] vect__analyzer=<function split_into_stems at 0x000002076DC30AE8>, vect__max_df=0.75, vect__min_df=1, vect__ngram_range=(1, 2) \n",
      "[CV]  vect__analyzer=<function split_into_stems at 0x000002076DC30AE8>, vect__max_df=0.75, vect__min_df=1, vect__ngram_range=(1, 2), score=0.8385117366319276, total=  43.5s\n",
      "[CV] vect__analyzer=<function split_into_stems at 0x000002076DC30AE8>, vect__max_df=0.75, vect__min_df=1, vect__ngram_range=(1, 2) \n",
      "[CV]  vect__analyzer=<function split_into_stems at 0x000002076DC30AE8>, vect__max_df=0.75, vect__min_df=1, vect__ngram_range=(1, 2), score=0.8311580792831401, total=  41.4s\n",
      "[CV] vect__analyzer=<function split_into_stems at 0x000002076DC30AE8>, vect__max_df=0.75, vect__min_df=2, vect__ngram_range=(1, 1) \n",
      "[CV]  vect__analyzer=<function split_into_stems at 0x000002076DC30AE8>, vect__max_df=0.75, vect__min_df=2, vect__ngram_range=(1, 1), score=0.8353542731921111, total=  42.6s\n",
      "[CV] vect__analyzer=<function split_into_stems at 0x000002076DC30AE8>, vect__max_df=0.75, vect__min_df=2, vect__ngram_range=(1, 1) \n",
      "[CV]  vect__analyzer=<function split_into_stems at 0x000002076DC30AE8>, vect__max_df=0.75, vect__min_df=2, vect__ngram_range=(1, 1), score=0.8331547677023473, total=  41.0s\n",
      "[CV] vect__analyzer=<function split_into_stems at 0x000002076DC30AE8>, vect__max_df=0.75, vect__min_df=2, vect__ngram_range=(1, 1) \n",
      "[CV]  vect__analyzer=<function split_into_stems at 0x000002076DC30AE8>, vect__max_df=0.75, vect__min_df=2, vect__ngram_range=(1, 1), score=0.829843186909516, total=  41.5s\n",
      "[CV] vect__analyzer=<function split_into_stems at 0x000002076DC30AE8>, vect__max_df=0.75, vect__min_df=2, vect__ngram_range=(1, 2) \n",
      "[CV]  vect__analyzer=<function split_into_stems at 0x000002076DC30AE8>, vect__max_df=0.75, vect__min_df=2, vect__ngram_range=(1, 2), score=0.8353542731921111, total=  43.2s\n",
      "[CV] vect__analyzer=<function split_into_stems at 0x000002076DC30AE8>, vect__max_df=0.75, vect__min_df=2, vect__ngram_range=(1, 2) \n",
      "[CV]  vect__analyzer=<function split_into_stems at 0x000002076DC30AE8>, vect__max_df=0.75, vect__min_df=2, vect__ngram_range=(1, 2), score=0.8331547677023473, total=  46.3s\n",
      "[CV] vect__analyzer=<function split_into_stems at 0x000002076DC30AE8>, vect__max_df=0.75, vect__min_df=2, vect__ngram_range=(1, 2) \n",
      "[CV]  vect__analyzer=<function split_into_stems at 0x000002076DC30AE8>, vect__max_df=0.75, vect__min_df=2, vect__ngram_range=(1, 2), score=0.829843186909516, total=  43.5s\n",
      "[CV] vect__analyzer=<function split_into_stems at 0x000002076DC30AE8>, vect__max_df=0.75, vect__min_df=3, vect__ngram_range=(1, 1) \n",
      "[CV]  vect__analyzer=<function split_into_stems at 0x000002076DC30AE8>, vect__max_df=0.75, vect__min_df=3, vect__ngram_range=(1, 1), score=0.8313610908205503, total=  41.0s\n",
      "[CV] vect__analyzer=<function split_into_stems at 0x000002076DC30AE8>, vect__max_df=0.75, vect__min_df=3, vect__ngram_range=(1, 1) \n",
      "[CV]  vect__analyzer=<function split_into_stems at 0x000002076DC30AE8>, vect__max_df=0.75, vect__min_df=3, vect__ngram_range=(1, 1), score=0.8306223823901822, total=  42.4s\n",
      "[CV] vect__analyzer=<function split_into_stems at 0x000002076DC30AE8>, vect__max_df=0.75, vect__min_df=3, vect__ngram_range=(1, 1) \n",
      "[CV]  vect__analyzer=<function split_into_stems at 0x000002076DC30AE8>, vect__max_df=0.75, vect__min_df=3, vect__ngram_range=(1, 1), score=0.8260933086588098, total=  43.5s\n",
      "[CV] vect__analyzer=<function split_into_stems at 0x000002076DC30AE8>, vect__max_df=0.75, vect__min_df=3, vect__ngram_range=(1, 2) \n",
      "[CV]  vect__analyzer=<function split_into_stems at 0x000002076DC30AE8>, vect__max_df=0.75, vect__min_df=3, vect__ngram_range=(1, 2), score=0.8313610908205503, total=  42.8s\n",
      "[CV] vect__analyzer=<function split_into_stems at 0x000002076DC30AE8>, vect__max_df=0.75, vect__min_df=3, vect__ngram_range=(1, 2) \n",
      "[CV]  vect__analyzer=<function split_into_stems at 0x000002076DC30AE8>, vect__max_df=0.75, vect__min_df=3, vect__ngram_range=(1, 2), score=0.8306223823901822, total=  48.3s\n",
      "[CV] vect__analyzer=<function split_into_stems at 0x000002076DC30AE8>, vect__max_df=0.75, vect__min_df=3, vect__ngram_range=(1, 2) \n",
      "[CV]  vect__analyzer=<function split_into_stems at 0x000002076DC30AE8>, vect__max_df=0.75, vect__min_df=3, vect__ngram_range=(1, 2), score=0.8260933086588098, total=  40.8s\n",
      "[CV] vect__analyzer=<function split_into_stems at 0x000002076DC30AE8>, vect__max_df=1.0, vect__min_df=1, vect__ngram_range=(1, 1) \n",
      "[CV]  vect__analyzer=<function split_into_stems at 0x000002076DC30AE8>, vect__max_df=1.0, vect__min_df=1, vect__ngram_range=(1, 1), score=0.8363769174579986, total=  42.0s\n",
      "[CV] vect__analyzer=<function split_into_stems at 0x000002076DC30AE8>, vect__max_df=1.0, vect__min_df=1, vect__ngram_range=(1, 1) \n",
      "[CV]  vect__analyzer=<function split_into_stems at 0x000002076DC30AE8>, vect__max_df=1.0, vect__min_df=1, vect__ngram_range=(1, 1), score=0.8391935326775105, total=  44.9s\n",
      "[CV] vect__analyzer=<function split_into_stems at 0x000002076DC30AE8>, vect__max_df=1.0, vect__min_df=1, vect__ngram_range=(1, 1) \n",
      "[CV]  vect__analyzer=<function split_into_stems at 0x000002076DC30AE8>, vect__max_df=1.0, vect__min_df=1, vect__ngram_range=(1, 1), score=0.8328138696795558, total=  45.5s\n",
      "[CV] vect__analyzer=<function split_into_stems at 0x000002076DC30AE8>, vect__max_df=1.0, vect__min_df=1, vect__ngram_range=(1, 2) \n",
      "[CV]  vect__analyzer=<function split_into_stems at 0x000002076DC30AE8>, vect__max_df=1.0, vect__min_df=1, vect__ngram_range=(1, 2), score=0.8363769174579986, total=  43.6s\n",
      "[CV] vect__analyzer=<function split_into_stems at 0x000002076DC30AE8>, vect__max_df=1.0, vect__min_df=1, vect__ngram_range=(1, 2) \n",
      "[CV]  vect__analyzer=<function split_into_stems at 0x000002076DC30AE8>, vect__max_df=1.0, vect__min_df=1, vect__ngram_range=(1, 2), score=0.8391935326775105, total=  45.8s\n",
      "[CV] vect__analyzer=<function split_into_stems at 0x000002076DC30AE8>, vect__max_df=1.0, vect__min_df=1, vect__ngram_range=(1, 2) \n",
      "[CV]  vect__analyzer=<function split_into_stems at 0x000002076DC30AE8>, vect__max_df=1.0, vect__min_df=1, vect__ngram_range=(1, 2), score=0.8328138696795558, total=  51.3s\n",
      "[CV] vect__analyzer=<function split_into_stems at 0x000002076DC30AE8>, vect__max_df=1.0, vect__min_df=2, vect__ngram_range=(1, 1) \n",
      "[CV]  vect__analyzer=<function split_into_stems at 0x000002076DC30AE8>, vect__max_df=1.0, vect__min_df=2, vect__ngram_range=(1, 1), score=0.8354516678841003, total=  51.1s\n",
      "[CV] vect__analyzer=<function split_into_stems at 0x000002076DC30AE8>, vect__max_df=1.0, vect__min_df=2, vect__ngram_range=(1, 1) \n",
      "[CV]  vect__analyzer=<function split_into_stems at 0x000002076DC30AE8>, vect__max_df=1.0, vect__min_df=2, vect__ngram_range=(1, 1), score=0.8342261614882633, total=  54.1s\n",
      "[CV] vect__analyzer=<function split_into_stems at 0x000002076DC30AE8>, vect__max_df=1.0, vect__min_df=2, vect__ngram_range=(1, 1) \n",
      "[CV]  vect__analyzer=<function split_into_stems at 0x000002076DC30AE8>, vect__max_df=1.0, vect__min_df=2, vect__ngram_range=(1, 1), score=0.8288204928411416, total=  54.6s\n",
      "[CV] vect__analyzer=<function split_into_stems at 0x000002076DC30AE8>, vect__max_df=1.0, vect__min_df=2, vect__ngram_range=(1, 2) \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV]  vect__analyzer=<function split_into_stems at 0x000002076DC30AE8>, vect__max_df=1.0, vect__min_df=2, vect__ngram_range=(1, 2), score=0.8354516678841003, total=  56.9s\n",
      "[CV] vect__analyzer=<function split_into_stems at 0x000002076DC30AE8>, vect__max_df=1.0, vect__min_df=2, vect__ngram_range=(1, 2) \n",
      "[CV]  vect__analyzer=<function split_into_stems at 0x000002076DC30AE8>, vect__max_df=1.0, vect__min_df=2, vect__ngram_range=(1, 2), score=0.8342261614882633, total=  50.1s\n",
      "[CV] vect__analyzer=<function split_into_stems at 0x000002076DC30AE8>, vect__max_df=1.0, vect__min_df=2, vect__ngram_range=(1, 2) \n",
      "[CV]  vect__analyzer=<function split_into_stems at 0x000002076DC30AE8>, vect__max_df=1.0, vect__min_df=2, vect__ngram_range=(1, 2), score=0.8288204928411416, total=  43.1s\n",
      "[CV] vect__analyzer=<function split_into_stems at 0x000002076DC30AE8>, vect__max_df=1.0, vect__min_df=3, vect__ngram_range=(1, 1) \n",
      "[CV]  vect__analyzer=<function split_into_stems at 0x000002076DC30AE8>, vect__max_df=1.0, vect__min_df=3, vect__ngram_range=(1, 1), score=0.8307767226686146, total=  45.9s\n",
      "[CV] vect__analyzer=<function split_into_stems at 0x000002076DC30AE8>, vect__max_df=1.0, vect__min_df=3, vect__ngram_range=(1, 1) \n",
      "[CV]  vect__analyzer=<function split_into_stems at 0x000002076DC30AE8>, vect__max_df=1.0, vect__min_df=3, vect__ngram_range=(1, 1), score=0.8316937761760982, total=  47.1s\n",
      "[CV] vect__analyzer=<function split_into_stems at 0x000002076DC30AE8>, vect__max_df=1.0, vect__min_df=3, vect__ngram_range=(1, 1) \n",
      "[CV]  vect__analyzer=<function split_into_stems at 0x000002076DC30AE8>, vect__max_df=1.0, vect__min_df=3, vect__ngram_range=(1, 1), score=0.8260446089412682, total=  54.7s\n",
      "[CV] vect__analyzer=<function split_into_stems at 0x000002076DC30AE8>, vect__max_df=1.0, vect__min_df=3, vect__ngram_range=(1, 2) \n",
      "[CV]  vect__analyzer=<function split_into_stems at 0x000002076DC30AE8>, vect__max_df=1.0, vect__min_df=3, vect__ngram_range=(1, 2), score=0.8307767226686146, total= 1.0min\n",
      "[CV] vect__analyzer=<function split_into_stems at 0x000002076DC30AE8>, vect__max_df=1.0, vect__min_df=3, vect__ngram_range=(1, 2) \n",
      "[CV]  vect__analyzer=<function split_into_stems at 0x000002076DC30AE8>, vect__max_df=1.0, vect__min_df=3, vect__ngram_range=(1, 2), score=0.8316937761760982, total=  49.0s\n",
      "[CV] vect__analyzer=<function split_into_stems at 0x000002076DC30AE8>, vect__max_df=1.0, vect__min_df=3, vect__ngram_range=(1, 2) \n",
      "[CV]  vect__analyzer=<function split_into_stems at 0x000002076DC30AE8>, vect__max_df=1.0, vect__min_df=3, vect__ngram_range=(1, 2), score=0.8260446089412682, total=  46.7s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Done  72 out of  72 | elapsed: 89.9min finished\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "GridSearchCV(cv=3, error_score='raise',\n",
       "       estimator=Pipeline(memory=None,\n",
       "     steps=[('vect', CountVectorizer(analyzer='word', binary=False, decode_error='strict',\n",
       "        dtype=<class 'numpy.int64'>, encoding='utf-8', input='content',\n",
       "        lowercase=True, max_df=1.0, max_features=None, min_df=1,\n",
       "        ngram_range=(1, 1), preprocessor=None, stop_words=None,\n",
       "        strip_accents=None, token_pattern='(?u)\\\\b\\\\w\\\\w+\\\\b',\n",
       "        tokenizer=None, vocabulary=None)), ('clf', MultinomialNB(alpha=1.0, class_prior=None, fit_prior=True))]),\n",
       "       fit_params=None, iid=True, n_jobs=1,\n",
       "       param_grid={'vect__analyzer': (<function split_into_lemmas at 0x000002077A15F7B8>, <function split_into_stems at 0x000002076DC30AE8>), 'vect__max_df': (0.75, 1.0), 'vect__min_df': (1, 2, 3), 'vect__ngram_range': ((1, 1), (1, 2))},\n",
       "       pre_dispatch='2*n_jobs', refit=True, return_train_score='warn',\n",
       "       scoring=None, verbose=10)"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "grid_search = GridSearchCV(estimator=pipeline,\n",
    "                           param_grid=parameters,\n",
    "                           cv=3,\n",
    "                           verbose=10)\n",
    "\n",
    "grid_search.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Print out the results of my gridsearch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best score: 0.836\n",
      "Best parameters set:\n",
      "\tvect__analyzer: <function split_into_stems at 0x000002076DC30AE8>\n",
      "\tvect__max_df: 1.0\n",
      "\tvect__min_df: 1\n",
      "\tvect__ngram_range: (1, 1)\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.81      0.90      0.85     10258\n",
      "          1       0.89      0.78      0.83     10277\n",
      "\n",
      "avg / total       0.85      0.84      0.84     20535\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(\"Best score: %0.3f\" % grid_search.best_score_)\n",
    "print(\"Best parameters set:\")\n",
    "best_parameters = grid_search.best_estimator_.get_params()\n",
    "for param_name in sorted(parameters.keys()):\n",
    "    print(\"\\t%s: %r\" % (param_name, best_parameters[param_name]))\n",
    "print(metrics.classification_report(y_test, grid_search.predict(X_test)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Add in the stop words and see that our results aren't much different"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.81      0.90      0.85     10258\n",
      "          1       0.89      0.78      0.83     10277\n",
      "\n",
      "avg / total       0.85      0.84      0.84     20535\n",
      "\n"
     ]
    }
   ],
   "source": [
    "vect = CountVectorizer(analyzer=split_into_stems, max_df=1.0, min_df=1, stop_words=stemmed_stops, ngram_range=(1,1))\n",
    "X_train_dtm = vect.fit_transform(X_train)\n",
    "X_test_dtm = vect.transform(X_test)\n",
    "nb = MultinomialNB()\n",
    "nb.fit(X_train_dtm, y_train)\n",
    "y_pred_class = nb.predict(X_test_dtm)\n",
    "print(metrics.classification_report(y_test, y_pred_class))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now I want some functions to further explore my resulting model. First I define a function that lets me grab tweets and print them. Then I'm going to look at what tweets look like that were falsely marked as trolls or not"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "def grab_tweet(tweet):\n",
    "    print(\"Author:\", tweet['author'])\n",
    "    print(\"Probability troll:\", tweet['proba_troll'])\n",
    "    print(\"Tweet text:\", tweet['content'])\n",
    "    print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_dtm = vect.transform(df_Trolls_News['content'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "proba = nb.predict_proba(df_dtm)\n",
    "df_Trolls_News['proba_troll'] = proba[:,1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Most Troll Like\n",
      "Author: nytimes\n",
      "Probability troll: 0.9999999745969038\n",
      "Tweet text: RT @jennydeluxe: \"Being black in the age of wokeness\" is one of my fave episodes to date. Listen &amp; LMK what you think &gt;&gt;&gt;&gt; https://t.co/r4T…\n",
      "\n",
      "Author: USATODAY\n",
      "Probability troll: 0.9999999433271982\n",
      "Tweet text: \"All I really want to do is tell you that I'm feeling great. I'm glad I spent that evening in the hospital, and it did me a lot of good.\" -Stan Lee https://t.co/JZg09bqS1g\n",
      "\n",
      "Author: FoxNews\n",
      "Probability troll: 0.9999997658795213\n",
      "Tweet text: .@POTUS on Democrats: \"I don't think they want to solve the DACA problem. I think they wanna talk about it. I think they wanna obstruct.\" https://t.co/zBPxHDzk6E\n",
      "\n",
      "Author: FoxNews\n",
      "Probability troll: 0.9999995789219475\n",
      "Tweet text: Huckabee: \"The greatest single characteristic of people on the far left is they have zero sense of humor. I mean, these are the most bitter, angry, really disappointing and disgusting people because they're so sad with life. I've never seen a group of people that are so unhappy.\" https://t.co/7tugSKNYzO\n",
      "\n",
      "Author: FoxNews\n",
      "Probability troll: 0.9999981327368727\n",
      "Tweet text: .@POTUS to U.S. servicemembers: \"We support you. We thank you. We love you and we will always have your back like you have ours. Thank you.\" https://t.co/oBJa5dDnnh\n",
      "\n",
      "Least Troll Like\n",
      "Author: politico\n",
      "Probability troll: 3.6591453955058484e-16\n",
      "Tweet text: Larry Kudlow has been widely seen as a leading candidate to replace Gary Cohn, despite his criticism of Trump’s decision to impose a 10 percent tariff on aluminum and 25 percent tariff on steel imports.\n",
      " https://t.co/f3A12AevZU https://t.co/wpgmLzoh4p\n",
      "\n",
      "Author: Reuters\n",
      "Probability troll: 1.4128334707379797e-15\n",
      "Tweet text: North Korean leader Kim Jong Un invites South Korean President Moon Jae-in to Pyongyang potentially setting up the first meeting of Korean leaders in more than a decade https://t.co/K7PvzMSyIA @HeeShin @pearswick #PyeongChang2018 https://t.co/kUseNlZ7g2\n",
      "\n",
      "Author: HuffPost\n",
      "Probability troll: 5.961917113556281e-15\n",
      "Tweet text: PyeongChang built itself a brand-new $109 million stadium to host the 2018 Winter Olympic and Paralympic Games. \n",
      "\n",
      "And after just four ceremonial events ― including the #OpeningCeremony ― PyeongChang plans to tear the place down. 🤔🤔🤔\n",
      "\n",
      "Here's more: https://t.co/QnNcDktTVs\n",
      "\n",
      "Author: ABC\n",
      "Probability troll: 1.2651090830925194e-14\n",
      "Tweet text: Students at Marjory Stoneman Douglas High School in Parkland, Florida, where 17 people were killed in a deadly shooting last month, walk out of their classrooms to protest for stricter gun laws as part of #NationalWalkoutDay. https://t.co/JuOWURifIL https://t.co/RVDU3en5Er\n",
      "\n",
      "Author: ABC\n",
      "Probability troll: 4.262461293689432e-14\n",
      "Tweet text: JUST IN: Yulia Skripal, daughter of former Russian spy Sergei Skripal, has been discharged from hospital in the UK five weeks after nerve agent attack, reports say. https://t.co/2OFbVimjO1 https://t.co/bQgd6CoIpx\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "147799    None\n",
       "135104    None\n",
       "136099    None\n",
       "147265    None\n",
       "132540    None\n",
       "dtype: object"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print(\"Most Troll Like\")\n",
    "df_Trolls_News.loc[df_Trolls_News.account_category_Troll==0].sort_values(by='proba_troll', ascending=False).head().apply(grab_tweet, axis=1)\n",
    "print(\"Least Troll Like\")\n",
    "df_Trolls_News.loc[df_Trolls_News.account_category_Troll==0].sort_values(by='proba_troll', ascending=True).head().apply(grab_tweet, axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Most News Like\n",
      "Author: KANIJJACKSON\n",
      "Probability troll: 3.7776428745550067e-08\n",
      "Tweet text: Confirmed: Michael Cohen received hundreds of thousands of dollars  from a Russian oligarch Viktor Vekselberg.  The money was paid to a First Republic Bank account Cohen created  for Essential Consultants. This is the same bank  account Cohen used to pay Stormy Daniels $130,000\n",
      "\n",
      "Author: IMAPHARRELFAKE\n",
      "Probability troll: 2.4569481184123893e-07\n",
      "Tweet text: Former Cuban President Fidel Castro dies at age 90, his brother, President Raul Castro announces. https://t.co/gHGSyRFlBi\n",
      "\n",
      "Author: COVFEFENATIONUS\n",
      "Probability troll: 7.531496579616669e-07\n",
      "Tweet text: Randall Saito was arrested in Stockton, CA this morning, per  San Joaquin Co Sheriff’s FB page  SJCO credits “a tip from an alert taxi cab driver”  Saito escaped from Hawaii State Hospital on Oahu,caught a taxi to the Honolulu airport, chartered a flight to Maui, then flew to CA\n",
      "\n",
      "Author: FIGHTTORESIST\n",
      "Probability troll: 2.249889063318448e-06\n",
      "Tweet text: #Trump has given up on his pledge to balance the #budget: The proposal would add $7.2 trillion more to the #debt over 10 years. The proposal still manages to implement austere cuts to many agencies, with the exceptions of the Defense, Veterans Affairs, and Homeland Security.\n",
      "\n",
      "Author: WORLDNEWSPOLI\n",
      "Probability troll: 2.449381509993957e-06\n",
      "Tweet text: Bao Bao the giant panda leaves Washington zoo for new home in China https://t.co/e6WNrKcrMI https://t.co/QnCVIUb3nQ\n",
      "\n",
      "Least News Like\n",
      "Author: MARISSAIMSTRONG\n",
      "Probability troll: 1.0\n",
      "Tweet text: RT @Shooters_Wife: MT @911USA1: Obamaism - good is evil and evil good! @WildBillUSA #tcot #TeaParty https://t.co/zGT3xW8kSc #WakeUpAmerica …\n",
      "\n",
      "Author: 4MYSQUAD\n",
      "Probability troll: 1.0\n",
      "Tweet text: '@hogrider30 so ya far from perfection than... haha ya piece of shit  juss scream all around THESE NIGGAZ OH FUCK EM!but we did to u NOTHING.'\n",
      "\n",
      "Author: IIDDAAMARKS\n",
      "Probability troll: 1.0\n",
      "Tweet text: #WhitePrivilege Debate Benefits White Liberals Not Black Americans https://t.co/fk6EmnTwtW  #PJNET #tcot #ccot #WakeUpAmerica #BlackTwitter\n",
      "\n",
      "Author: COVFEFENATIONUS\n",
      "Probability troll: 1.0\n",
      "Tweet text: '@Acosta @jaketapper @CNN @CNNI @CNNPolitics @CNNSitRoom @WolfBlitzer @JakeTapper @TheLeadCNN @BrianStelter @AnaNavarro @DonLemon @VanJones68 @AndersonCooper @AC360 @JimAcosta  CNN IS #FAKENEWS! CNN IS #FAKENEWS! CNN IS #FAKENEWS! CNN IS #FAKENEWS! CNN IS #FAKENEWS! CNN IS #FAKENEWS!  #FAKENEWS #MAGA'\n",
      "\n",
      "Author: EMILEEWAREN\n",
      "Probability troll: 1.0\n",
      "Tweet text: '@wrow51 @diane_kristal @TerjePeders1 @annastef62 @Rockies6020111 @Ohboyboy22 @john_jakester @GlennMcmillan14 @Penmebaby @SeamusGorman1 @DeplorableVetrn @KerriganConnery @deejayndn @jacquie_1959 @MajKangaroo @Swimmingly_ @CaptainNemo3000 @raulsemail7 @rldewen @costellodaniel1 @D6plus @nihilobstat23 @bo_canut @MyOpinyn @WANGNGEO @Johndm1952 @CarolHusband @reneewoods3 @yoforti @mnd89815 @themadsloth @lynxsee @TimMcAdams1984 @Smadello69 @EffieGib @mer4All @peterdiane01 @Paola_Dec1231 @Anubis716 @Dontvoteliberal @bigdaddy69780 @jack Because goats also should be respected. @jack https://t.co/yJ3vKPLPta'\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "38591    None\n",
       "14485    None\n",
       "19947    None\n",
       "27469    None\n",
       "35863    None\n",
       "dtype: object"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print(\"Most News Like\")\n",
    "df_Trolls_News.loc[df_Trolls_News.account_category_Troll==1].sort_values(by='proba_troll', ascending=True).head().apply(grab_tweet, axis=1)\n",
    "print(\"Least News Like\")\n",
    "df_Trolls_News.loc[df_Trolls_News.account_category_Troll==1].sort_values(by='proba_troll', ascending=False).head().apply(grab_tweet, axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "author\n",
       "Reuters           0.017009\n",
       "AP                0.018675\n",
       "chicagotribune    0.042039\n",
       "ABC               0.046095\n",
       "WSJ               0.054319\n",
       "politico          0.060109\n",
       "NPR               0.076523\n",
       "CNN               0.097069\n",
       "USATODAY          0.118057\n",
       "nytimes           0.128135\n",
       "washingtonpost    0.130681\n",
       "Forbes            0.138451\n",
       "FoxNews           0.171251\n",
       "nypost            0.185465\n",
       "HuffPost          0.222791\n",
       "Name: proba_troll, dtype: float64"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_Trolls_News.loc[df_Trolls_News.account_category_Troll==0].groupby(by='author').mean().proba_troll.sort_values()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
