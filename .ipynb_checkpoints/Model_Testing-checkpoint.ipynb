{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package stopwords to\n",
      "[nltk_data]     C:\\Users\\599701\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import scipy as sp\n",
    "\n",
    "from pprint import pprint\n",
    "from time import time\n",
    "from textblob import TextBlob, Word\n",
    "\n",
    "import logging\n",
    "from nltk.stem.snowball import SnowballStemmer\n",
    "from nltk.corpus import stopwords\n",
    "import nltk\n",
    "nltk.download('stopwords')\n",
    "\n",
    "from sklearn.model_selection import train_test_split as tts\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "from sklearn.naive_bayes import MultinomialNB         # Naive Bayes\n",
    "from sklearn import metrics\n",
    "\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.pipeline import Pipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "tweet_data = pd.read_csv(\"./datasets/combined_data.csv\", sep=\";\", \n",
    "                         dtype={'tweet_id':str, 'author_id':str, 'publish_date':str, \n",
    "                                'content':str, 'link_url':str, 'account_category':str, \n",
    "                                'author':str, 'account_type':str})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "tweet_data = pd.get_dummies(tweet_data, columns=['account_category'], drop_first=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_Troll = tweet_data[tweet_data.account_category_Troll == 1]\n",
    "df_Pol = tweet_data[tweet_data.account_category_Politician == 1]\n",
    "df_News = tweet_data[tweet_data.account_category_US_News == 1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(41069, 12)\n",
      "(41066, 12)\n",
      "(41069, 12)\n"
     ]
    }
   ],
   "source": [
    "print(df_Troll.shape)\n",
    "print(df_Pol.shape)\n",
    "print(df_News.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Some different testing sets\n",
    "df_Trolls_News = pd.concat([df_Troll, df_News])\n",
    "df_Trolls_Pol = pd.concat([df_Troll, df_Pol])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We'll start by comparing trolls and news outlets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = df_Trolls_News['content']\n",
    "y = df_Trolls_News['account_category_Troll']\n",
    "X_train, X_test, y_train, y_test = tts(X, y, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define a function that accepts text and returns a list of stems.\n",
    "stemmer = SnowballStemmer('english')\n",
    "def split_into_stems(text):\n",
    "    text = str(text).lower()\n",
    "    words = TextBlob(text).words\n",
    "    return [stemmer.stem(word) for word in words]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "stemmed_stops = [stemmer.stem(Word(x)) for x in stopwords.words('english')]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define a function that accepts text and returns a list of lemmas.\n",
    "def split_into_lemmas(text):\n",
    "    text = str(text).lower()\n",
    "    words = TextBlob(text).words\n",
    "    return [word.lemmatize() for word in words]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "lemmed_stops = [Word(x).lemmatize() for x in stopwords.words('english')]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "pipeline = Pipeline([\n",
    "    ('vect', CountVectorizer()),\n",
    "    ('clf', MultinomialNB())])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "parameters = {\n",
    "    'vect__analyzer': (split_into_lemmas, split_into_stems, None),\n",
    "    'vect__max_df': (0.5, 0.75, 1.0),\n",
    "    'vect__min_df': (1, 2, 3),\n",
    "    #'vect__max_features': (None, 5000, 10000, 50000),\n",
    "    'vect__ngram_range': ((1, 1), (1, 2))  # unigrams or bigrams\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 3 folds for each of 54 candidates, totalling 162 fits\n",
      "[CV] vect__analyzer=<function split_into_lemmas at 0x000002077A15F7B8>, vect__max_df=0.5, vect__min_df=1, vect__ngram_range=(1, 1) \n",
      "[CV]  vect__analyzer=<function split_into_lemmas at 0x000002077A15F7B8>, vect__max_df=0.5, vect__min_df=1, vect__ngram_range=(1, 1), score=0.8319941563184806, total=  38.2s\n",
      "[CV] vect__analyzer=<function split_into_lemmas at 0x000002077A15F7B8>, vect__max_df=0.5, vect__min_df=1, vect__ngram_range=(1, 1) \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:  1.1min remaining:    0.0s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV]  vect__analyzer=<function split_into_lemmas at 0x000002077A15F7B8>, vect__max_df=0.5, vect__min_df=1, vect__ngram_range=(1, 1), score=0.8322294730690561, total=  54.6s\n",
      "[CV] vect__analyzer=<function split_into_lemmas at 0x000002077A15F7B8>, vect__max_df=0.5, vect__min_df=1, vect__ngram_range=(1, 1) \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Done   2 out of   2 | elapsed:  2.5min remaining:    0.0s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV]  vect__analyzer=<function split_into_lemmas at 0x000002077A15F7B8>, vect__max_df=0.5, vect__min_df=1, vect__ngram_range=(1, 1), score=0.8259472095061848, total=  49.3s\n",
      "[CV] vect__analyzer=<function split_into_lemmas at 0x000002077A15F7B8>, vect__max_df=0.5, vect__min_df=1, vect__ngram_range=(1, 2) \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Done   3 out of   3 | elapsed:  3.8min remaining:    0.0s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV]  vect__analyzer=<function split_into_lemmas at 0x000002077A15F7B8>, vect__max_df=0.5, vect__min_df=1, vect__ngram_range=(1, 2), score=0.8319941563184806, total=  45.9s\n",
      "[CV] vect__analyzer=<function split_into_lemmas at 0x000002077A15F7B8>, vect__max_df=0.5, vect__min_df=1, vect__ngram_range=(1, 2) \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Done   4 out of   4 | elapsed:  5.0min remaining:    0.0s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV]  vect__analyzer=<function split_into_lemmas at 0x000002077A15F7B8>, vect__max_df=0.5, vect__min_df=1, vect__ngram_range=(1, 2), score=0.8322294730690561, total=  39.6s\n",
      "[CV] vect__analyzer=<function split_into_lemmas at 0x000002077A15F7B8>, vect__max_df=0.5, vect__min_df=1, vect__ngram_range=(1, 2) \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Done   5 out of   5 | elapsed:  6.1min remaining:    0.0s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV]  vect__analyzer=<function split_into_lemmas at 0x000002077A15F7B8>, vect__max_df=0.5, vect__min_df=1, vect__ngram_range=(1, 2), score=0.8259472095061848, total=  42.5s\n",
      "[CV] vect__analyzer=<function split_into_lemmas at 0x000002077A15F7B8>, vect__max_df=0.5, vect__min_df=2, vect__ngram_range=(1, 1) \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Done   6 out of   6 | elapsed:  7.3min remaining:    0.0s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV]  vect__analyzer=<function split_into_lemmas at 0x000002077A15F7B8>, vect__max_df=0.5, vect__min_df=2, vect__ngram_range=(1, 1), score=0.8287314341368396, total=  39.6s\n",
      "[CV] vect__analyzer=<function split_into_lemmas at 0x000002077A15F7B8>, vect__max_df=0.5, vect__min_df=2, vect__ngram_range=(1, 1) \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Done   7 out of   7 | elapsed:  8.4min remaining:    0.0s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV]  vect__analyzer=<function split_into_lemmas at 0x000002077A15F7B8>, vect__max_df=0.5, vect__min_df=2, vect__ngram_range=(1, 1), score=0.827943897925392, total=  41.7s\n",
      "[CV] vect__analyzer=<function split_into_lemmas at 0x000002077A15F7B8>, vect__max_df=0.5, vect__min_df=2, vect__ngram_range=(1, 1) \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Done   8 out of   8 | elapsed:  9.5min remaining:    0.0s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV]  vect__analyzer=<function split_into_lemmas at 0x000002077A15F7B8>, vect__max_df=0.5, vect__min_df=2, vect__ngram_range=(1, 1), score=0.821759033797604, total=  36.4s\n",
      "[CV] vect__analyzer=<function split_into_lemmas at 0x000002077A15F7B8>, vect__max_df=0.5, vect__min_df=2, vect__ngram_range=(1, 2) \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Done   9 out of   9 | elapsed: 10.5min remaining:    0.0s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV]  vect__analyzer=<function split_into_lemmas at 0x000002077A15F7B8>, vect__max_df=0.5, vect__min_df=2, vect__ngram_range=(1, 2), score=0.8287314341368396, total=  35.6s\n",
      "[CV] vect__analyzer=<function split_into_lemmas at 0x000002077A15F7B8>, vect__max_df=0.5, vect__min_df=2, vect__ngram_range=(1, 2) \n",
      "[CV]  vect__analyzer=<function split_into_lemmas at 0x000002077A15F7B8>, vect__max_df=0.5, vect__min_df=2, vect__ngram_range=(1, 2), score=0.827943897925392, total=  42.2s\n",
      "[CV] vect__analyzer=<function split_into_lemmas at 0x000002077A15F7B8>, vect__max_df=0.5, vect__min_df=2, vect__ngram_range=(1, 2) \n",
      "[CV]  vect__analyzer=<function split_into_lemmas at 0x000002077A15F7B8>, vect__max_df=0.5, vect__min_df=2, vect__ngram_range=(1, 2), score=0.821759033797604, total=  37.6s\n",
      "[CV] vect__analyzer=<function split_into_lemmas at 0x000002077A15F7B8>, vect__max_df=0.5, vect__min_df=3, vect__ngram_range=(1, 1) \n",
      "[CV]  vect__analyzer=<function split_into_lemmas at 0x000002077A15F7B8>, vect__max_df=0.5, vect__min_df=3, vect__ngram_range=(1, 1), score=0.8230338446554663, total=  36.1s\n",
      "[CV] vect__analyzer=<function split_into_lemmas at 0x000002077A15F7B8>, vect__max_df=0.5, vect__min_df=3, vect__ngram_range=(1, 1) \n",
      "[CV]  vect__analyzer=<function split_into_lemmas at 0x000002077A15F7B8>, vect__max_df=0.5, vect__min_df=3, vect__ngram_range=(1, 1), score=0.824583617415019, total=  40.3s\n",
      "[CV] vect__analyzer=<function split_into_lemmas at 0x000002077A15F7B8>, vect__max_df=0.5, vect__min_df=3, vect__ngram_range=(1, 1) \n",
      "[CV]  vect__analyzer=<function split_into_lemmas at 0x000002077A15F7B8>, vect__max_df=0.5, vect__min_df=3, vect__ngram_range=(1, 1), score=0.8180578552644394, total=  32.5s\n",
      "[CV] vect__analyzer=<function split_into_lemmas at 0x000002077A15F7B8>, vect__max_df=0.5, vect__min_df=3, vect__ngram_range=(1, 2) \n",
      "[CV]  vect__analyzer=<function split_into_lemmas at 0x000002077A15F7B8>, vect__max_df=0.5, vect__min_df=3, vect__ngram_range=(1, 2), score=0.8230338446554663, total=  32.7s\n",
      "[CV] vect__analyzer=<function split_into_lemmas at 0x000002077A15F7B8>, vect__max_df=0.5, vect__min_df=3, vect__ngram_range=(1, 2) \n",
      "[CV]  vect__analyzer=<function split_into_lemmas at 0x000002077A15F7B8>, vect__max_df=0.5, vect__min_df=3, vect__ngram_range=(1, 2), score=0.824583617415019, total=  33.5s\n",
      "[CV] vect__analyzer=<function split_into_lemmas at 0x000002077A15F7B8>, vect__max_df=0.5, vect__min_df=3, vect__ngram_range=(1, 2) \n",
      "[CV]  vect__analyzer=<function split_into_lemmas at 0x000002077A15F7B8>, vect__max_df=0.5, vect__min_df=3, vect__ngram_range=(1, 2), score=0.8180578552644394, total=  32.9s\n",
      "[CV] vect__analyzer=<function split_into_lemmas at 0x000002077A15F7B8>, vect__max_df=0.75, vect__min_df=1, vect__ngram_range=(1, 1) \n",
      "[CV]  vect__analyzer=<function split_into_lemmas at 0x000002077A15F7B8>, vect__max_df=0.75, vect__min_df=1, vect__ngram_range=(1, 1), score=0.8319941563184806, total=  33.0s\n",
      "[CV] vect__analyzer=<function split_into_lemmas at 0x000002077A15F7B8>, vect__max_df=0.75, vect__min_df=1, vect__ngram_range=(1, 1) \n",
      "[CV]  vect__analyzer=<function split_into_lemmas at 0x000002077A15F7B8>, vect__max_df=0.75, vect__min_df=1, vect__ngram_range=(1, 1), score=0.8322294730690561, total=  33.1s\n",
      "[CV] vect__analyzer=<function split_into_lemmas at 0x000002077A15F7B8>, vect__max_df=0.75, vect__min_df=1, vect__ngram_range=(1, 1) \n",
      "[CV]  vect__analyzer=<function split_into_lemmas at 0x000002077A15F7B8>, vect__max_df=0.75, vect__min_df=1, vect__ngram_range=(1, 1), score=0.8259472095061848, total=  33.7s\n",
      "[CV] vect__analyzer=<function split_into_lemmas at 0x000002077A15F7B8>, vect__max_df=0.75, vect__min_df=1, vect__ngram_range=(1, 2) \n",
      "[CV]  vect__analyzer=<function split_into_lemmas at 0x000002077A15F7B8>, vect__max_df=0.75, vect__min_df=1, vect__ngram_range=(1, 2), score=0.8319941563184806, total=  32.7s\n",
      "[CV] vect__analyzer=<function split_into_lemmas at 0x000002077A15F7B8>, vect__max_df=0.75, vect__min_df=1, vect__ngram_range=(1, 2) \n",
      "[CV]  vect__analyzer=<function split_into_lemmas at 0x000002077A15F7B8>, vect__max_df=0.75, vect__min_df=1, vect__ngram_range=(1, 2), score=0.8322294730690561, total=  33.0s\n",
      "[CV] vect__analyzer=<function split_into_lemmas at 0x000002077A15F7B8>, vect__max_df=0.75, vect__min_df=1, vect__ngram_range=(1, 2) \n",
      "[CV]  vect__analyzer=<function split_into_lemmas at 0x000002077A15F7B8>, vect__max_df=0.75, vect__min_df=1, vect__ngram_range=(1, 2), score=0.8259472095061848, total=  32.4s\n",
      "[CV] vect__analyzer=<function split_into_lemmas at 0x000002077A15F7B8>, vect__max_df=0.75, vect__min_df=2, vect__ngram_range=(1, 1) \n",
      "[CV]  vect__analyzer=<function split_into_lemmas at 0x000002077A15F7B8>, vect__max_df=0.75, vect__min_df=2, vect__ngram_range=(1, 1), score=0.8287314341368396, total=  32.6s\n",
      "[CV] vect__analyzer=<function split_into_lemmas at 0x000002077A15F7B8>, vect__max_df=0.75, vect__min_df=2, vect__ngram_range=(1, 1) \n",
      "[CV]  vect__analyzer=<function split_into_lemmas at 0x000002077A15F7B8>, vect__max_df=0.75, vect__min_df=2, vect__ngram_range=(1, 1), score=0.827943897925392, total=  32.5s\n",
      "[CV] vect__analyzer=<function split_into_lemmas at 0x000002077A15F7B8>, vect__max_df=0.75, vect__min_df=2, vect__ngram_range=(1, 1) \n",
      "[CV]  vect__analyzer=<function split_into_lemmas at 0x000002077A15F7B8>, vect__max_df=0.75, vect__min_df=2, vect__ngram_range=(1, 1), score=0.821759033797604, total=  32.8s\n",
      "[CV] vect__analyzer=<function split_into_lemmas at 0x000002077A15F7B8>, vect__max_df=0.75, vect__min_df=2, vect__ngram_range=(1, 2) \n",
      "[CV]  vect__analyzer=<function split_into_lemmas at 0x000002077A15F7B8>, vect__max_df=0.75, vect__min_df=2, vect__ngram_range=(1, 2), score=0.8287314341368396, total=  32.9s\n",
      "[CV] vect__analyzer=<function split_into_lemmas at 0x000002077A15F7B8>, vect__max_df=0.75, vect__min_df=2, vect__ngram_range=(1, 2) \n",
      "[CV]  vect__analyzer=<function split_into_lemmas at 0x000002077A15F7B8>, vect__max_df=0.75, vect__min_df=2, vect__ngram_range=(1, 2), score=0.827943897925392, total=  32.7s\n",
      "[CV] vect__analyzer=<function split_into_lemmas at 0x000002077A15F7B8>, vect__max_df=0.75, vect__min_df=2, vect__ngram_range=(1, 2) \n",
      "[CV]  vect__analyzer=<function split_into_lemmas at 0x000002077A15F7B8>, vect__max_df=0.75, vect__min_df=2, vect__ngram_range=(1, 2), score=0.821759033797604, total=  32.6s\n",
      "[CV] vect__analyzer=<function split_into_lemmas at 0x000002077A15F7B8>, vect__max_df=0.75, vect__min_df=3, vect__ngram_range=(1, 1) \n",
      "[CV]  vect__analyzer=<function split_into_lemmas at 0x000002077A15F7B8>, vect__max_df=0.75, vect__min_df=3, vect__ngram_range=(1, 1), score=0.8230338446554663, total=  32.5s\n",
      "[CV] vect__analyzer=<function split_into_lemmas at 0x000002077A15F7B8>, vect__max_df=0.75, vect__min_df=3, vect__ngram_range=(1, 1) \n",
      "[CV]  vect__analyzer=<function split_into_lemmas at 0x000002077A15F7B8>, vect__max_df=0.75, vect__min_df=3, vect__ngram_range=(1, 1), score=0.824583617415019, total=  32.7s\n",
      "[CV] vect__analyzer=<function split_into_lemmas at 0x000002077A15F7B8>, vect__max_df=0.75, vect__min_df=3, vect__ngram_range=(1, 1) \n",
      "[CV]  vect__analyzer=<function split_into_lemmas at 0x000002077A15F7B8>, vect__max_df=0.75, vect__min_df=3, vect__ngram_range=(1, 1), score=0.8180578552644394, total=  32.4s\n",
      "[CV] vect__analyzer=<function split_into_lemmas at 0x000002077A15F7B8>, vect__max_df=0.75, vect__min_df=3, vect__ngram_range=(1, 2) \n",
      "[CV]  vect__analyzer=<function split_into_lemmas at 0x000002077A15F7B8>, vect__max_df=0.75, vect__min_df=3, vect__ngram_range=(1, 2), score=0.8230338446554663, total=  33.1s\n",
      "[CV] vect__analyzer=<function split_into_lemmas at 0x000002077A15F7B8>, vect__max_df=0.75, vect__min_df=3, vect__ngram_range=(1, 2) \n",
      "[CV]  vect__analyzer=<function split_into_lemmas at 0x000002077A15F7B8>, vect__max_df=0.75, vect__min_df=3, vect__ngram_range=(1, 2), score=0.824583617415019, total=  36.0s\n",
      "[CV] vect__analyzer=<function split_into_lemmas at 0x000002077A15F7B8>, vect__max_df=0.75, vect__min_df=3, vect__ngram_range=(1, 2) \n",
      "[CV]  vect__analyzer=<function split_into_lemmas at 0x000002077A15F7B8>, vect__max_df=0.75, vect__min_df=3, vect__ngram_range=(1, 2), score=0.8180578552644394, total=  35.5s\n",
      "[CV] vect__analyzer=<function split_into_lemmas at 0x000002077A15F7B8>, vect__max_df=1.0, vect__min_df=1, vect__ngram_range=(1, 1) \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV]  vect__analyzer=<function split_into_lemmas at 0x000002077A15F7B8>, vect__max_df=1.0, vect__min_df=1, vect__ngram_range=(1, 1), score=0.8309715120525931, total=  40.5s\n",
      "[CV] vect__analyzer=<function split_into_lemmas at 0x000002077A15F7B8>, vect__max_df=1.0, vect__min_df=1, vect__ngram_range=(1, 1) \n",
      "[CV]  vect__analyzer=<function split_into_lemmas at 0x000002077A15F7B8>, vect__max_df=1.0, vect__min_df=1, vect__ngram_range=(1, 1), score=0.8334956657251388, total=  45.0s\n",
      "[CV] vect__analyzer=<function split_into_lemmas at 0x000002077A15F7B8>, vect__max_df=1.0, vect__min_df=1, vect__ngram_range=(1, 1) \n",
      "[CV]  vect__analyzer=<function split_into_lemmas at 0x000002077A15F7B8>, vect__max_df=1.0, vect__min_df=1, vect__ngram_range=(1, 1), score=0.8255576117658517, total=  40.3s\n",
      "[CV] vect__analyzer=<function split_into_lemmas at 0x000002077A15F7B8>, vect__max_df=1.0, vect__min_df=1, vect__ngram_range=(1, 2) \n"
     ]
    }
   ],
   "source": [
    "grid_search = GridSearchCV(estimator=pipeline,\n",
    "                           param_grid=parameters,\n",
    "                           cv=3,\n",
    "                           verbose=10)\n",
    "\n",
    "grid_search.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Best score: %0.3f\" % grid_search.best_score_)\n",
    "print(\"Best parameters set:\")\n",
    "best_parameters = grid_search.best_estimator_.get_params()\n",
    "for param_name in sorted(parameters.keys()):\n",
    "    print(\"\\t%s: %r\" % (param_name, best_parameters[param_name]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def print_top10(vectorizer, clf, class_labels):\n",
    "    \"\"\"Prints features with the highest coefficient values, per class\"\"\"\n",
    "    feature_names = vectorizer.get_feature_names()\n",
    "    for i, class_label in enumerate(class_labels):\n",
    "        top10 = np.argsort(clf.coef_[i])[-10:]\n",
    "        print(\"%s: %s\" % (class_label,\n",
    "              \" \".join(feature_names[j] for j in top10)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def grab_tweet(tweet):\n",
    "    print(\"Author:\", tweet['author'])\n",
    "    print(\"Probability troll:\", tweet['proba_troll'])\n",
    "    print(\"Tweet text:\", tweet['content'])\n",
    "    print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_dtm = vect.transform(df_Trolls_News['content'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "proba = nb.predict_proba(df_dtm)\n",
    "df_Trolls_News['proba_troll'] = proba[:,1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Most Troll Like\")\n",
    "df_Trolls_News.loc[df_Trolls_News.account_category_Troll==0].sort_values(by='proba_troll', ascending=False).head().apply(grab_tweet, axis=1)\n",
    "print(\"Least Troll Like\")\n",
    "df_Trolls_News.loc[df_Trolls_News.account_category_Troll==0].sort_values(by='proba_troll', ascending=True).head().apply(grab_tweet, axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def grab_tweet(tweet):\n",
    "    print(\"Author:\", tweet['author'])\n",
    "    print(\"Probability troll:\", tweet['proba_troll'])\n",
    "    print(\"Tweet text:\", tweet['content'])\n",
    "    print()\n",
    "df_Trolls_News.loc[df_Trolls_News.account_category_Troll==0].sort_values(by='proba_troll', ascending=True).head().apply(grab_tweet, axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_Trolls_News.loc[df_Trolls_News.account_category_Troll==0].groupby(by='author').mean().proba_troll.sort_values()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = df_Trolls_Pol['content']\n",
    "y = df_Trolls_Pol['account_category_Troll']\n",
    "X_train, X_test, y_train, y_test = tts(X, y, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "vect = CountVectorizer(analyzer=split_into_lemmas, stop_words=lemmed_stops, min_df=2, max_df=.75)\n",
    "X_train_dtm = vect.fit_transform(X_train)\n",
    "X_test_dtm = vect.transform(X_test)\n",
    "nb = MultinomialNB()\n",
    "nb.fit(X_train_dtm, y_train)\n",
    "y_pred_class = nb.predict(X_test_dtm)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(metrics.classification_report(y_test, y_pred_class))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_dtm = vect.transform(df_Trolls_Pol['content'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "proba = nb.predict_proba(df_dtm)\n",
    "df_Trolls_Pol['proba_troll'] = proba[:,1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_Trolls_Pol.loc[df_Trolls_Pol.account_category_Troll==0].sort_values(by='proba_troll', ascending=False).head().apply(grab_tweet, axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_Trolls_Pol.loc[df_Trolls_Pol.account_category_Troll==0].groupby(by='author').mean().proba_troll.sort_values()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
