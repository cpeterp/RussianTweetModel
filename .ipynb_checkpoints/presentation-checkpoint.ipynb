{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "# Can we Identify Russian Trolls on Twitter?\n",
    "### By: Collin Pampalone"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "## Overview\n",
    "In recent years the media and politicians have been increasingly concerned about foreign influence of US media, especially by Russian Trolls. Social Media platforms such as Twitter provide enormous platforms for trolls to push different agendas. Domestic users of these platforms may be unknowingly bombarded by foreign rhetoric that ultimately affects their views on US politics. \n",
    "\n",
    "Many users of social media platforms, politicians, and news pundits have argued that the platforms have a responsibility to remove political trolls. But in an age where tweets are posted as rapidly as opinions are formed, how can platforms identify trolls? In my project I have created a learning model that identifies troll tweets from text alone. Using a similar model, social media platforms could remove or flag suspicious tweets as they are posted, helping mitigate the liability and reputation risk posed by trolls."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "skip"
    }
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import scipy as sp\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from pprint import pprint\n",
    "from time import time\n",
    "from textblob import TextBlob, Word\n",
    "\n",
    "import logging\n",
    "from nltk.stem.snowball import SnowballStemmer\n",
    "from nltk.corpus import stopwords\n",
    "import nltk\n",
    "nltk.download('stopwords')\n",
    "\n",
    "from sklearn.model_selection import train_test_split as tts\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "from sklearn.naive_bayes import MultinomialNB         # Naive Bayes\n",
    "from sklearn import metrics\n",
    "\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## Import\n",
    "I have already pulled and formated my data from external sources, so I simply need to import it into the notebook and extract the relavant features. Troll tweets were downloaded from FiveThirtyEight, non-trols were from scraped from twitter with Twarc and data from GWU. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "outputs": [],
   "source": [
    "tweet_data = pd.read_csv(\"./datasets/combined_data.csv\", sep=\";\", \n",
    "                         dtype={'tweet_id':str, 'author_id':str, 'publish_date':str, \n",
    "                                'content':str, 'link_url':str, 'account_category':str, \n",
    "                                'author':str, 'account_type':str})\n",
    "tweet_data = tweet_data.loc[(tweet_data.account_category == 'Troll') | (tweet_data.account_category == 'US_News')]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "outputs": [],
   "source": [
    "sns.heatmap(tweet_data.isnull(), yticklabels = False, cbar = False, cmap = \"viridis\");"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Inital EDA\n",
    "\n",
    "We want to check how the data is spead out."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false,
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "outputs": [],
   "source": [
    "plt.subplots(figsize=(10,6));\n",
    "sns.countplot(x=tweet_data['account_category'], hue=tweet_data['account_type']);"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "Let's take a look at the sentiment as well"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "outputs": [],
   "source": [
    "# Define a function that accepts text and returns the polarity.\n",
    "def detect_sentiment(text):\n",
    "    return TextBlob(text).sentiment.polarity\n",
    "\n",
    "tweet_data['sentiment'] = tweet_data.content.apply(detect_sentiment)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "outputs": [],
   "source": [
    "tweet_data.boxplot(column='sentiment', by='account_category');"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "outputs": [],
   "source": [
    "tweet_data.boxplot(column='sentiment', by='account_type');"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "The boxplots didn't show any significan difference. Next, use groupby to take a deeper dive into sentiment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true,
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "outputs": [],
   "source": [
    "tweet_data.groupby(by=['account_category', 'account_type']).describe()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## NLP Preperation\n",
    "Now to start using NLP. `account_category` is a categorical feature, so I need to turn it into binary features to make classification possible. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "outputs": [],
   "source": [
    "tweet_data = pd.get_dummies(tweet_data, columns=['account_category'], drop_first=False)\n",
    "df_Troll = tweet_data[tweet_data.account_category_Troll == 1]\n",
    "df_News = tweet_data[tweet_data.account_category_US_News == 1]\n",
    "\n",
    "df_Trolls_News = pd.concat([df_Troll, df_News])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "I need to stem the words in the tweet text as well. This will reduce the number of features and improve the performance of my a model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "outputs": [],
   "source": [
    "# Define a function that accepts text and returns a list of stems.\n",
    "stemmer = SnowballStemmer('english')\n",
    "def split_into_stems(text):\n",
    "    text = str(text).lower()\n",
    "    words = TextBlob(text).words\n",
    "    return [stemmer.stem(word) for word in words]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [],
   "source": [
    "stemmed_stops = [stemmer.stem(Word(x)) for x in stopwords.words('english')]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "Now I need to do the test-train-split and evaluate my results. The options for the model I chose were determined by a grid search."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "outputs": [],
   "source": [
    "X = df_Trolls_News['content']\n",
    "y = df_Trolls_News['account_category_Troll']\n",
    "X_train, X_test, y_train, y_test = tts(X, y, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "outputs": [],
   "source": [
    "vect = CountVectorizer(analyzer=split_into_stems, max_df=1.0, min_df=1, stop_words=stemmed_stops, ngram_range=(1,1))\n",
    "X_train_dtm = vect.fit_transform(X_train)\n",
    "X_test_dtm = vect.transform(X_test)\n",
    "nb = MultinomialNB()\n",
    "nb.fit(X_train_dtm, y_train)\n",
    "y_pred_class = nb.predict(X_test_dtm)\n",
    "print(metrics.classification_report(y_test, y_pred_class))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "outputs": [],
   "source": [
    "def grab_tweet(tweet):\n",
    "    print(\"Author:\", tweet['author'])\n",
    "    print(\"Probability troll:\", tweet['proba_troll'])\n",
    "    print(\"Tweet text:\", tweet['content'])\n",
    "    print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [],
   "source": [
    "df_dtm = vect.transform(df_Trolls_News['content'])\n",
    "proba = nb.predict_proba(df_dtm)\n",
    "df_Trolls_News['proba_troll'] = proba[:,1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "outputs": [],
   "source": [
    "print(\"Most Troll Like\")\n",
    "df_Trolls_News.loc[df_Trolls_News.account_category_Troll==0].sort_values(by='proba_troll', ascending=False).head(3).apply(grab_tweet, axis=1)\n",
    "print(\"-----------------------------------------------------------------------------------------------------------------------\")\n",
    "print(\"Least Troll Like\")\n",
    "df_Trolls_News.loc[df_Trolls_News.account_category_Troll==0].sort_values(by='proba_troll', ascending=True).head(3).apply(grab_tweet, axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "outputs": [],
   "source": [
    "print(\"Most News Like\")\n",
    "df_Trolls_News.loc[df_Trolls_News.account_category_Troll==1].sort_values(by='proba_troll', ascending=True).head().apply(grab_tweet, axis=1)\n",
    "print(\"-----------------------------------------------------------------------------------------------------------------------\")\n",
    "print(\"Least News Like\")\n",
    "df_Trolls_News.loc[df_Trolls_News.account_category_Troll==1].sort_values(by='proba_troll', ascending=False).head().apply(grab_tweet, axis=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "Finally, I want to take a look at how each news outlet scored on average"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "outputs": [],
   "source": [
    "df_Trolls_News.loc[df_Trolls_News.account_category_Troll==0].groupby(by='author').mean().proba_troll.sort_values()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## Conclusions\n",
    "\n",
    "Overall, I the model works pretty well. Given a 50/50 split, the model is able to predict trolls correctly 84% of the time.\n",
    "\n",
    "|Type     |precision|recall|f1-score|support|\n",
    "| ------- |:-------:|:----:|:------:|------:|\n",
    "|News     |0.81     |0.90  |0.85    |10258  |\n",
    "|Troll    |0.89     |0.78  |0.83    |10277  |"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "### Limitations\n",
    "\n",
    "* There was no deep dive into links, images (memes), or RTs. So the model does not account for how a tweet could be replying to another comment or promoting an article or even sharing/spreading a meme. However, these contain information that humans understand and can ultimately be influenced by\n",
    "\n",
    "* I used a limited sample of tweets to compare the trolls to. I.e. I only compared trolls to politicians active at the same time and news articles posted by a select group of outlets. However, in reality a social media platform contains a lot more noise - innocuous meme pages, advertisers, standard users. Not to mention domestic trolls and fake news accounts."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "### Future work\n",
    "\n",
    "A great application of the model could be a browser extension that allows users of twitter to quickly asses the likelihood that a tweet if from a troll. It could then allow the model to further train itself by accepting user feedback"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "celltoolbar": "Slideshow",
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
