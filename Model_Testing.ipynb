{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package stopwords to\n",
      "[nltk_data]     C:\\Users\\599701\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import scipy as sp\n",
    "\n",
    "from pprint import pprint\n",
    "from time import time\n",
    "from textblob import TextBlob, Word\n",
    "\n",
    "import logging\n",
    "from nltk.stem.snowball import SnowballStemmer\n",
    "from nltk.corpus import stopwords\n",
    "import nltk\n",
    "nltk.download('stopwords')\n",
    "\n",
    "from sklearn.model_selection import train_test_split as tts\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "from sklearn.naive_bayes import MultinomialNB         # Naive Bayes\n",
    "from sklearn import metrics\n",
    "\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.pipeline import Pipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "tweet_data = pd.read_csv(\"./datasets/combined_data.csv\", sep=\";\", \n",
    "                         dtype={'tweet_id':str, 'author_id':str, 'publish_date':str, \n",
    "                                'content':str, 'link_url':str, 'account_category':str, \n",
    "                                'author':str, 'account_type':str})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "tweet_data = pd.get_dummies(tweet_data, columns=['account_category'], drop_first=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_Troll = tweet_data[tweet_data.account_category_Troll == 1]\n",
    "df_Pol = tweet_data[tweet_data.account_category_Politician == 1]\n",
    "df_News = tweet_data[tweet_data.account_category_US_News == 1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(41069, 12)\n",
      "(41066, 12)\n",
      "(41069, 12)\n"
     ]
    }
   ],
   "source": [
    "print(df_Troll.shape)\n",
    "print(df_Pol.shape)\n",
    "print(df_News.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Some different testing sets\n",
    "df_Trolls_News = pd.concat([df_Troll, df_News])\n",
    "df_Trolls_Pol = pd.concat([df_Troll, df_Pol])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We'll start by comparing trolls and news outlets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = df_Trolls_News['content']\n",
    "y = df_Trolls_News['account_category_Troll']\n",
    "X_train, X_test, y_train, y_test = tts(X, y, random_state=42)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Define functions to stem or lemmatze text in a tweet. Also create the list of stop words to use with them."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define a function that accepts text and returns a list of stems.\n",
    "stemmer = SnowballStemmer('english')\n",
    "def split_into_stems(text):\n",
    "    text = str(text).lower()\n",
    "    words = TextBlob(text).words\n",
    "    return [stemmer.stem(word) for word in words]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "stemmed_stops = [stemmer.stem(Word(x)) for x in stopwords.words('english')]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define a function that accepts text and returns a list of lemmas.\n",
    "def split_into_lemmas(text):\n",
    "    text = str(text).lower()\n",
    "    words = TextBlob(text).words\n",
    "    return [word.lemmatize() for word in words]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "lemmed_stops = [Word(x).lemmatize() for x in stopwords.words('english')]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now I need to define the pipline and gridsearch parameters."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "pipeline = Pipeline([\n",
    "    ('vect', CountVectorizer()),\n",
    "    ('clf', MultinomialNB())])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "parameters = {\n",
    "    'vect__analyzer': (split_into_lemmas, split_into_stems),\n",
    "    'vect__max_df': (0.75, 1.0),\n",
    "    'vect__min_df': (1, 2, 3),\n",
    "    #'vect__max_features': (None, 5000, 10000, 50000),\n",
    "    'vect__ngram_range': ((1, 1), (1, 2))  # unigrams or bigrams\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 3 folds for each of 24 candidates, totalling 72 fits\n",
      "[CV] vect__analyzer=<function split_into_lemmas at 0x000002077A15F7B8>, vect__max_df=0.75, vect__min_df=1, vect__ngram_range=(1, 1) \n",
      "[CV]  vect__analyzer=<function split_into_lemmas at 0x000002077A15F7B8>, vect__max_df=0.75, vect__min_df=1, vect__ngram_range=(1, 1), score=0.8319941563184806, total=  36.4s\n",
      "[CV] vect__analyzer=<function split_into_lemmas at 0x000002077A15F7B8>, vect__max_df=0.75, vect__min_df=1, vect__ngram_range=(1, 1) \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:  1.0min remaining:    0.0s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV]  vect__analyzer=<function split_into_lemmas at 0x000002077A15F7B8>, vect__max_df=0.75, vect__min_df=1, vect__ngram_range=(1, 1), score=0.8322294730690561, total=  37.9s\n",
      "[CV] vect__analyzer=<function split_into_lemmas at 0x000002077A15F7B8>, vect__max_df=0.75, vect__min_df=1, vect__ngram_range=(1, 1) \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Done   2 out of   2 | elapsed:  2.1min remaining:    0.0s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV]  vect__analyzer=<function split_into_lemmas at 0x000002077A15F7B8>, vect__max_df=0.75, vect__min_df=1, vect__ngram_range=(1, 1), score=0.8259472095061848, total=  37.1s\n",
      "[CV] vect__analyzer=<function split_into_lemmas at 0x000002077A15F7B8>, vect__max_df=0.75, vect__min_df=1, vect__ngram_range=(1, 2) \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Done   3 out of   3 | elapsed:  3.1min remaining:    0.0s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV]  vect__analyzer=<function split_into_lemmas at 0x000002077A15F7B8>, vect__max_df=0.75, vect__min_df=1, vect__ngram_range=(1, 2), score=0.8319941563184806, total=  37.2s\n",
      "[CV] vect__analyzer=<function split_into_lemmas at 0x000002077A15F7B8>, vect__max_df=0.75, vect__min_df=1, vect__ngram_range=(1, 2) \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Done   4 out of   4 | elapsed:  4.1min remaining:    0.0s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV]  vect__analyzer=<function split_into_lemmas at 0x000002077A15F7B8>, vect__max_df=0.75, vect__min_df=1, vect__ngram_range=(1, 2), score=0.8322294730690561, total=  37.6s\n",
      "[CV] vect__analyzer=<function split_into_lemmas at 0x000002077A15F7B8>, vect__max_df=0.75, vect__min_df=1, vect__ngram_range=(1, 2) \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Done   5 out of   5 | elapsed:  5.2min remaining:    0.0s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV]  vect__analyzer=<function split_into_lemmas at 0x000002077A15F7B8>, vect__max_df=0.75, vect__min_df=1, vect__ngram_range=(1, 2), score=0.8259472095061848, total=  58.1s\n",
      "[CV] vect__analyzer=<function split_into_lemmas at 0x000002077A15F7B8>, vect__max_df=0.75, vect__min_df=2, vect__ngram_range=(1, 1) \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Done   6 out of   6 | elapsed:  6.6min remaining:    0.0s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV]  vect__analyzer=<function split_into_lemmas at 0x000002077A15F7B8>, vect__max_df=0.75, vect__min_df=2, vect__ngram_range=(1, 1), score=0.8287314341368396, total=  42.6s\n",
      "[CV] vect__analyzer=<function split_into_lemmas at 0x000002077A15F7B8>, vect__max_df=0.75, vect__min_df=2, vect__ngram_range=(1, 1) \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Done   7 out of   7 | elapsed:  7.8min remaining:    0.0s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV]  vect__analyzer=<function split_into_lemmas at 0x000002077A15F7B8>, vect__max_df=0.75, vect__min_df=2, vect__ngram_range=(1, 1), score=0.827943897925392, total=  39.9s\n",
      "[CV] vect__analyzer=<function split_into_lemmas at 0x000002077A15F7B8>, vect__max_df=0.75, vect__min_df=2, vect__ngram_range=(1, 1) \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Done   8 out of   8 | elapsed:  8.9min remaining:    0.0s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV]  vect__analyzer=<function split_into_lemmas at 0x000002077A15F7B8>, vect__max_df=0.75, vect__min_df=2, vect__ngram_range=(1, 1), score=0.821759033797604, total=  44.0s\n",
      "[CV] vect__analyzer=<function split_into_lemmas at 0x000002077A15F7B8>, vect__max_df=0.75, vect__min_df=2, vect__ngram_range=(1, 2) \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Done   9 out of   9 | elapsed: 10.1min remaining:    0.0s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV]  vect__analyzer=<function split_into_lemmas at 0x000002077A15F7B8>, vect__max_df=0.75, vect__min_df=2, vect__ngram_range=(1, 2), score=0.8287314341368396, total=  46.3s\n",
      "[CV] vect__analyzer=<function split_into_lemmas at 0x000002077A15F7B8>, vect__max_df=0.75, vect__min_df=2, vect__ngram_range=(1, 2) \n",
      "[CV]  vect__analyzer=<function split_into_lemmas at 0x000002077A15F7B8>, vect__max_df=0.75, vect__min_df=2, vect__ngram_range=(1, 2), score=0.827943897925392, total=  44.3s\n",
      "[CV] vect__analyzer=<function split_into_lemmas at 0x000002077A15F7B8>, vect__max_df=0.75, vect__min_df=2, vect__ngram_range=(1, 2) \n",
      "[CV]  vect__analyzer=<function split_into_lemmas at 0x000002077A15F7B8>, vect__max_df=0.75, vect__min_df=2, vect__ngram_range=(1, 2), score=0.821759033797604, total=  36.6s\n",
      "[CV] vect__analyzer=<function split_into_lemmas at 0x000002077A15F7B8>, vect__max_df=0.75, vect__min_df=3, vect__ngram_range=(1, 1) \n",
      "[CV]  vect__analyzer=<function split_into_lemmas at 0x000002077A15F7B8>, vect__max_df=0.75, vect__min_df=3, vect__ngram_range=(1, 1), score=0.8230338446554663, total=  45.7s\n",
      "[CV] vect__analyzer=<function split_into_lemmas at 0x000002077A15F7B8>, vect__max_df=0.75, vect__min_df=3, vect__ngram_range=(1, 1) \n",
      "[CV]  vect__analyzer=<function split_into_lemmas at 0x000002077A15F7B8>, vect__max_df=0.75, vect__min_df=3, vect__ngram_range=(1, 1), score=0.824583617415019, total=  39.1s\n",
      "[CV] vect__analyzer=<function split_into_lemmas at 0x000002077A15F7B8>, vect__max_df=0.75, vect__min_df=3, vect__ngram_range=(1, 1) \n",
      "[CV]  vect__analyzer=<function split_into_lemmas at 0x000002077A15F7B8>, vect__max_df=0.75, vect__min_df=3, vect__ngram_range=(1, 1), score=0.8180578552644394, total=  49.4s\n",
      "[CV] vect__analyzer=<function split_into_lemmas at 0x000002077A15F7B8>, vect__max_df=0.75, vect__min_df=3, vect__ngram_range=(1, 2) \n",
      "[CV]  vect__analyzer=<function split_into_lemmas at 0x000002077A15F7B8>, vect__max_df=0.75, vect__min_df=3, vect__ngram_range=(1, 2), score=0.8230338446554663, total=  48.9s\n",
      "[CV] vect__analyzer=<function split_into_lemmas at 0x000002077A15F7B8>, vect__max_df=0.75, vect__min_df=3, vect__ngram_range=(1, 2) \n",
      "[CV]  vect__analyzer=<function split_into_lemmas at 0x000002077A15F7B8>, vect__max_df=0.75, vect__min_df=3, vect__ngram_range=(1, 2), score=0.824583617415019, total=  50.0s\n",
      "[CV] vect__analyzer=<function split_into_lemmas at 0x000002077A15F7B8>, vect__max_df=0.75, vect__min_df=3, vect__ngram_range=(1, 2) \n",
      "[CV]  vect__analyzer=<function split_into_lemmas at 0x000002077A15F7B8>, vect__max_df=0.75, vect__min_df=3, vect__ngram_range=(1, 2), score=0.8180578552644394, total=  35.1s\n",
      "[CV] vect__analyzer=<function split_into_lemmas at 0x000002077A15F7B8>, vect__max_df=1.0, vect__min_df=1, vect__ngram_range=(1, 1) \n",
      "[CV]  vect__analyzer=<function split_into_lemmas at 0x000002077A15F7B8>, vect__max_df=1.0, vect__min_df=1, vect__ngram_range=(1, 1), score=0.8309715120525931, total=  35.8s\n",
      "[CV] vect__analyzer=<function split_into_lemmas at 0x000002077A15F7B8>, vect__max_df=1.0, vect__min_df=1, vect__ngram_range=(1, 1) \n",
      "[CV]  vect__analyzer=<function split_into_lemmas at 0x000002077A15F7B8>, vect__max_df=1.0, vect__min_df=1, vect__ngram_range=(1, 1), score=0.8334956657251388, total=  43.1s\n",
      "[CV] vect__analyzer=<function split_into_lemmas at 0x000002077A15F7B8>, vect__max_df=1.0, vect__min_df=1, vect__ngram_range=(1, 1) \n",
      "[CV]  vect__analyzer=<function split_into_lemmas at 0x000002077A15F7B8>, vect__max_df=1.0, vect__min_df=1, vect__ngram_range=(1, 1), score=0.8255576117658517, total=  40.8s\n",
      "[CV] vect__analyzer=<function split_into_lemmas at 0x000002077A15F7B8>, vect__max_df=1.0, vect__min_df=1, vect__ngram_range=(1, 2) \n",
      "[CV]  vect__analyzer=<function split_into_lemmas at 0x000002077A15F7B8>, vect__max_df=1.0, vect__min_df=1, vect__ngram_range=(1, 2), score=0.8309715120525931, total=  37.6s\n",
      "[CV] vect__analyzer=<function split_into_lemmas at 0x000002077A15F7B8>, vect__max_df=1.0, vect__min_df=1, vect__ngram_range=(1, 2) \n",
      "[CV]  vect__analyzer=<function split_into_lemmas at 0x000002077A15F7B8>, vect__max_df=1.0, vect__min_df=1, vect__ngram_range=(1, 2), score=0.8334956657251388, total=  41.1s\n",
      "[CV] vect__analyzer=<function split_into_lemmas at 0x000002077A15F7B8>, vect__max_df=1.0, vect__min_df=1, vect__ngram_range=(1, 2) \n",
      "[CV]  vect__analyzer=<function split_into_lemmas at 0x000002077A15F7B8>, vect__max_df=1.0, vect__min_df=1, vect__ngram_range=(1, 2), score=0.8255576117658517, total=  40.2s\n",
      "[CV] vect__analyzer=<function split_into_lemmas at 0x000002077A15F7B8>, vect__max_df=1.0, vect__min_df=2, vect__ngram_range=(1, 1) \n",
      "[CV]  vect__analyzer=<function split_into_lemmas at 0x000002077A15F7B8>, vect__max_df=1.0, vect__min_df=2, vect__ngram_range=(1, 1), score=0.8287314341368396, total=  43.9s\n",
      "[CV] vect__analyzer=<function split_into_lemmas at 0x000002077A15F7B8>, vect__max_df=1.0, vect__min_df=2, vect__ngram_range=(1, 1) \n",
      "[CV]  vect__analyzer=<function split_into_lemmas at 0x000002077A15F7B8>, vect__max_df=1.0, vect__min_df=2, vect__ngram_range=(1, 1), score=0.8281873965131002, total=  41.6s\n",
      "[CV] vect__analyzer=<function split_into_lemmas at 0x000002077A15F7B8>, vect__max_df=1.0, vect__min_df=2, vect__ngram_range=(1, 1) \n",
      "[CV]  vect__analyzer=<function split_into_lemmas at 0x000002077A15F7B8>, vect__max_df=1.0, vect__min_df=2, vect__ngram_range=(1, 1), score=0.8211259374695626, total=  43.5s\n",
      "[CV] vect__analyzer=<function split_into_lemmas at 0x000002077A15F7B8>, vect__max_df=1.0, vect__min_df=2, vect__ngram_range=(1, 2) \n",
      "[CV]  vect__analyzer=<function split_into_lemmas at 0x000002077A15F7B8>, vect__max_df=1.0, vect__min_df=2, vect__ngram_range=(1, 2), score=0.8287314341368396, total=  44.2s\n",
      "[CV] vect__analyzer=<function split_into_lemmas at 0x000002077A15F7B8>, vect__max_df=1.0, vect__min_df=2, vect__ngram_range=(1, 2) \n",
      "[CV]  vect__analyzer=<function split_into_lemmas at 0x000002077A15F7B8>, vect__max_df=1.0, vect__min_df=2, vect__ngram_range=(1, 2), score=0.8281873965131002, total= 1.2min\n",
      "[CV] vect__analyzer=<function split_into_lemmas at 0x000002077A15F7B8>, vect__max_df=1.0, vect__min_df=2, vect__ngram_range=(1, 2) \n",
      "[CV]  vect__analyzer=<function split_into_lemmas at 0x000002077A15F7B8>, vect__max_df=1.0, vect__min_df=2, vect__ngram_range=(1, 2), score=0.8211259374695626, total=  58.1s\n",
      "[CV] vect__analyzer=<function split_into_lemmas at 0x000002077A15F7B8>, vect__max_df=1.0, vect__min_df=3, vect__ngram_range=(1, 1) \n",
      "[CV]  vect__analyzer=<function split_into_lemmas at 0x000002077A15F7B8>, vect__max_df=1.0, vect__min_df=3, vect__ngram_range=(1, 1), score=0.8241538836133431, total=  39.5s\n",
      "[CV] vect__analyzer=<function split_into_lemmas at 0x000002077A15F7B8>, vect__max_df=1.0, vect__min_df=3, vect__ngram_range=(1, 1) \n",
      "[CV]  vect__analyzer=<function split_into_lemmas at 0x000002077A15F7B8>, vect__max_df=1.0, vect__min_df=3, vect__ngram_range=(1, 1), score=0.8257037109184767, total=  40.0s\n",
      "[CV] vect__analyzer=<function split_into_lemmas at 0x000002077A15F7B8>, vect__max_df=1.0, vect__min_df=3, vect__ngram_range=(1, 1) \n",
      "[CV]  vect__analyzer=<function split_into_lemmas at 0x000002077A15F7B8>, vect__max_df=1.0, vect__min_df=3, vect__ngram_range=(1, 1), score=0.8183013538521476, total=  43.9s\n",
      "[CV] vect__analyzer=<function split_into_lemmas at 0x000002077A15F7B8>, vect__max_df=1.0, vect__min_df=3, vect__ngram_range=(1, 2) \n",
      "[CV]  vect__analyzer=<function split_into_lemmas at 0x000002077A15F7B8>, vect__max_df=1.0, vect__min_df=3, vect__ngram_range=(1, 2), score=0.8241538836133431, total=  43.5s\n",
      "[CV] vect__analyzer=<function split_into_lemmas at 0x000002077A15F7B8>, vect__max_df=1.0, vect__min_df=3, vect__ngram_range=(1, 2) \n",
      "[CV]  vect__analyzer=<function split_into_lemmas at 0x000002077A15F7B8>, vect__max_df=1.0, vect__min_df=3, vect__ngram_range=(1, 2), score=0.8257037109184767, total=  44.6s\n",
      "[CV] vect__analyzer=<function split_into_lemmas at 0x000002077A15F7B8>, vect__max_df=1.0, vect__min_df=3, vect__ngram_range=(1, 2) \n",
      "[CV]  vect__analyzer=<function split_into_lemmas at 0x000002077A15F7B8>, vect__max_df=1.0, vect__min_df=3, vect__ngram_range=(1, 2), score=0.8183013538521476, total=  45.0s\n",
      "[CV] vect__analyzer=<function split_into_stems at 0x000002076DC30AE8>, vect__max_df=0.75, vect__min_df=1, vect__ngram_range=(1, 1) \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV]  vect__analyzer=<function split_into_stems at 0x000002076DC30AE8>, vect__max_df=0.75, vect__min_df=1, vect__ngram_range=(1, 1), score=0.8378378378378378, total=  54.4s\n",
      "[CV] vect__analyzer=<function split_into_stems at 0x000002076DC30AE8>, vect__max_df=0.75, vect__min_df=1, vect__ngram_range=(1, 1) \n",
      "[CV]  vect__analyzer=<function split_into_stems at 0x000002076DC30AE8>, vect__max_df=0.75, vect__min_df=1, vect__ngram_range=(1, 1), score=0.8385117366319276, total=  56.1s\n",
      "[CV] vect__analyzer=<function split_into_stems at 0x000002076DC30AE8>, vect__max_df=0.75, vect__min_df=1, vect__ngram_range=(1, 1) \n",
      "[CV]  vect__analyzer=<function split_into_stems at 0x000002076DC30AE8>, vect__max_df=0.75, vect__min_df=1, vect__ngram_range=(1, 1), score=0.8311580792831401, total=  47.7s\n",
      "[CV] vect__analyzer=<function split_into_stems at 0x000002076DC30AE8>, vect__max_df=0.75, vect__min_df=1, vect__ngram_range=(1, 2) \n",
      "[CV]  vect__analyzer=<function split_into_stems at 0x000002076DC30AE8>, vect__max_df=0.75, vect__min_df=1, vect__ngram_range=(1, 2), score=0.8378378378378378, total=  42.8s\n",
      "[CV] vect__analyzer=<function split_into_stems at 0x000002076DC30AE8>, vect__max_df=0.75, vect__min_df=1, vect__ngram_range=(1, 2) \n",
      "[CV]  vect__analyzer=<function split_into_stems at 0x000002076DC30AE8>, vect__max_df=0.75, vect__min_df=1, vect__ngram_range=(1, 2), score=0.8385117366319276, total=  43.5s\n",
      "[CV] vect__analyzer=<function split_into_stems at 0x000002076DC30AE8>, vect__max_df=0.75, vect__min_df=1, vect__ngram_range=(1, 2) \n",
      "[CV]  vect__analyzer=<function split_into_stems at 0x000002076DC30AE8>, vect__max_df=0.75, vect__min_df=1, vect__ngram_range=(1, 2), score=0.8311580792831401, total=  41.4s\n",
      "[CV] vect__analyzer=<function split_into_stems at 0x000002076DC30AE8>, vect__max_df=0.75, vect__min_df=2, vect__ngram_range=(1, 1) \n",
      "[CV]  vect__analyzer=<function split_into_stems at 0x000002076DC30AE8>, vect__max_df=0.75, vect__min_df=2, vect__ngram_range=(1, 1), score=0.8353542731921111, total=  42.6s\n",
      "[CV] vect__analyzer=<function split_into_stems at 0x000002076DC30AE8>, vect__max_df=0.75, vect__min_df=2, vect__ngram_range=(1, 1) \n",
      "[CV]  vect__analyzer=<function split_into_stems at 0x000002076DC30AE8>, vect__max_df=0.75, vect__min_df=2, vect__ngram_range=(1, 1), score=0.8331547677023473, total=  41.0s\n",
      "[CV] vect__analyzer=<function split_into_stems at 0x000002076DC30AE8>, vect__max_df=0.75, vect__min_df=2, vect__ngram_range=(1, 1) \n",
      "[CV]  vect__analyzer=<function split_into_stems at 0x000002076DC30AE8>, vect__max_df=0.75, vect__min_df=2, vect__ngram_range=(1, 1), score=0.829843186909516, total=  41.5s\n",
      "[CV] vect__analyzer=<function split_into_stems at 0x000002076DC30AE8>, vect__max_df=0.75, vect__min_df=2, vect__ngram_range=(1, 2) \n",
      "[CV]  vect__analyzer=<function split_into_stems at 0x000002076DC30AE8>, vect__max_df=0.75, vect__min_df=2, vect__ngram_range=(1, 2), score=0.8353542731921111, total=  43.2s\n",
      "[CV] vect__analyzer=<function split_into_stems at 0x000002076DC30AE8>, vect__max_df=0.75, vect__min_df=2, vect__ngram_range=(1, 2) \n",
      "[CV]  vect__analyzer=<function split_into_stems at 0x000002076DC30AE8>, vect__max_df=0.75, vect__min_df=2, vect__ngram_range=(1, 2), score=0.8331547677023473, total=  46.3s\n",
      "[CV] vect__analyzer=<function split_into_stems at 0x000002076DC30AE8>, vect__max_df=0.75, vect__min_df=2, vect__ngram_range=(1, 2) \n",
      "[CV]  vect__analyzer=<function split_into_stems at 0x000002076DC30AE8>, vect__max_df=0.75, vect__min_df=2, vect__ngram_range=(1, 2), score=0.829843186909516, total=  43.5s\n",
      "[CV] vect__analyzer=<function split_into_stems at 0x000002076DC30AE8>, vect__max_df=0.75, vect__min_df=3, vect__ngram_range=(1, 1) \n",
      "[CV]  vect__analyzer=<function split_into_stems at 0x000002076DC30AE8>, vect__max_df=0.75, vect__min_df=3, vect__ngram_range=(1, 1), score=0.8313610908205503, total=  41.0s\n",
      "[CV] vect__analyzer=<function split_into_stems at 0x000002076DC30AE8>, vect__max_df=0.75, vect__min_df=3, vect__ngram_range=(1, 1) \n",
      "[CV]  vect__analyzer=<function split_into_stems at 0x000002076DC30AE8>, vect__max_df=0.75, vect__min_df=3, vect__ngram_range=(1, 1), score=0.8306223823901822, total=  42.4s\n",
      "[CV] vect__analyzer=<function split_into_stems at 0x000002076DC30AE8>, vect__max_df=0.75, vect__min_df=3, vect__ngram_range=(1, 1) \n",
      "[CV]  vect__analyzer=<function split_into_stems at 0x000002076DC30AE8>, vect__max_df=0.75, vect__min_df=3, vect__ngram_range=(1, 1), score=0.8260933086588098, total=  43.5s\n",
      "[CV] vect__analyzer=<function split_into_stems at 0x000002076DC30AE8>, vect__max_df=0.75, vect__min_df=3, vect__ngram_range=(1, 2) \n",
      "[CV]  vect__analyzer=<function split_into_stems at 0x000002076DC30AE8>, vect__max_df=0.75, vect__min_df=3, vect__ngram_range=(1, 2), score=0.8313610908205503, total=  42.8s\n",
      "[CV] vect__analyzer=<function split_into_stems at 0x000002076DC30AE8>, vect__max_df=0.75, vect__min_df=3, vect__ngram_range=(1, 2) \n",
      "[CV]  vect__analyzer=<function split_into_stems at 0x000002076DC30AE8>, vect__max_df=0.75, vect__min_df=3, vect__ngram_range=(1, 2), score=0.8306223823901822, total=  48.3s\n",
      "[CV] vect__analyzer=<function split_into_stems at 0x000002076DC30AE8>, vect__max_df=0.75, vect__min_df=3, vect__ngram_range=(1, 2) \n",
      "[CV]  vect__analyzer=<function split_into_stems at 0x000002076DC30AE8>, vect__max_df=0.75, vect__min_df=3, vect__ngram_range=(1, 2), score=0.8260933086588098, total=  40.8s\n",
      "[CV] vect__analyzer=<function split_into_stems at 0x000002076DC30AE8>, vect__max_df=1.0, vect__min_df=1, vect__ngram_range=(1, 1) \n",
      "[CV]  vect__analyzer=<function split_into_stems at 0x000002076DC30AE8>, vect__max_df=1.0, vect__min_df=1, vect__ngram_range=(1, 1), score=0.8363769174579986, total=  42.0s\n",
      "[CV] vect__analyzer=<function split_into_stems at 0x000002076DC30AE8>, vect__max_df=1.0, vect__min_df=1, vect__ngram_range=(1, 1) \n",
      "[CV]  vect__analyzer=<function split_into_stems at 0x000002076DC30AE8>, vect__max_df=1.0, vect__min_df=1, vect__ngram_range=(1, 1), score=0.8391935326775105, total=  44.9s\n",
      "[CV] vect__analyzer=<function split_into_stems at 0x000002076DC30AE8>, vect__max_df=1.0, vect__min_df=1, vect__ngram_range=(1, 1) \n",
      "[CV]  vect__analyzer=<function split_into_stems at 0x000002076DC30AE8>, vect__max_df=1.0, vect__min_df=1, vect__ngram_range=(1, 1), score=0.8328138696795558, total=  45.5s\n",
      "[CV] vect__analyzer=<function split_into_stems at 0x000002076DC30AE8>, vect__max_df=1.0, vect__min_df=1, vect__ngram_range=(1, 2) \n",
      "[CV]  vect__analyzer=<function split_into_stems at 0x000002076DC30AE8>, vect__max_df=1.0, vect__min_df=1, vect__ngram_range=(1, 2), score=0.8363769174579986, total=  43.6s\n",
      "[CV] vect__analyzer=<function split_into_stems at 0x000002076DC30AE8>, vect__max_df=1.0, vect__min_df=1, vect__ngram_range=(1, 2) \n",
      "[CV]  vect__analyzer=<function split_into_stems at 0x000002076DC30AE8>, vect__max_df=1.0, vect__min_df=1, vect__ngram_range=(1, 2), score=0.8391935326775105, total=  45.8s\n",
      "[CV] vect__analyzer=<function split_into_stems at 0x000002076DC30AE8>, vect__max_df=1.0, vect__min_df=1, vect__ngram_range=(1, 2) \n",
      "[CV]  vect__analyzer=<function split_into_stems at 0x000002076DC30AE8>, vect__max_df=1.0, vect__min_df=1, vect__ngram_range=(1, 2), score=0.8328138696795558, total=  51.3s\n",
      "[CV] vect__analyzer=<function split_into_stems at 0x000002076DC30AE8>, vect__max_df=1.0, vect__min_df=2, vect__ngram_range=(1, 1) \n",
      "[CV]  vect__analyzer=<function split_into_stems at 0x000002076DC30AE8>, vect__max_df=1.0, vect__min_df=2, vect__ngram_range=(1, 1), score=0.8354516678841003, total=  51.1s\n",
      "[CV] vect__analyzer=<function split_into_stems at 0x000002076DC30AE8>, vect__max_df=1.0, vect__min_df=2, vect__ngram_range=(1, 1) \n",
      "[CV]  vect__analyzer=<function split_into_stems at 0x000002076DC30AE8>, vect__max_df=1.0, vect__min_df=2, vect__ngram_range=(1, 1), score=0.8342261614882633, total=  54.1s\n",
      "[CV] vect__analyzer=<function split_into_stems at 0x000002076DC30AE8>, vect__max_df=1.0, vect__min_df=2, vect__ngram_range=(1, 1) \n",
      "[CV]  vect__analyzer=<function split_into_stems at 0x000002076DC30AE8>, vect__max_df=1.0, vect__min_df=2, vect__ngram_range=(1, 1), score=0.8288204928411416, total=  54.6s\n",
      "[CV] vect__analyzer=<function split_into_stems at 0x000002076DC30AE8>, vect__max_df=1.0, vect__min_df=2, vect__ngram_range=(1, 2) \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV]  vect__analyzer=<function split_into_stems at 0x000002076DC30AE8>, vect__max_df=1.0, vect__min_df=2, vect__ngram_range=(1, 2), score=0.8354516678841003, total=  56.9s\n",
      "[CV] vect__analyzer=<function split_into_stems at 0x000002076DC30AE8>, vect__max_df=1.0, vect__min_df=2, vect__ngram_range=(1, 2) \n",
      "[CV]  vect__analyzer=<function split_into_stems at 0x000002076DC30AE8>, vect__max_df=1.0, vect__min_df=2, vect__ngram_range=(1, 2), score=0.8342261614882633, total=  50.1s\n",
      "[CV] vect__analyzer=<function split_into_stems at 0x000002076DC30AE8>, vect__max_df=1.0, vect__min_df=2, vect__ngram_range=(1, 2) \n",
      "[CV]  vect__analyzer=<function split_into_stems at 0x000002076DC30AE8>, vect__max_df=1.0, vect__min_df=2, vect__ngram_range=(1, 2), score=0.8288204928411416, total=  43.1s\n",
      "[CV] vect__analyzer=<function split_into_stems at 0x000002076DC30AE8>, vect__max_df=1.0, vect__min_df=3, vect__ngram_range=(1, 1) \n",
      "[CV]  vect__analyzer=<function split_into_stems at 0x000002076DC30AE8>, vect__max_df=1.0, vect__min_df=3, vect__ngram_range=(1, 1), score=0.8307767226686146, total=  45.9s\n",
      "[CV] vect__analyzer=<function split_into_stems at 0x000002076DC30AE8>, vect__max_df=1.0, vect__min_df=3, vect__ngram_range=(1, 1) \n",
      "[CV]  vect__analyzer=<function split_into_stems at 0x000002076DC30AE8>, vect__max_df=1.0, vect__min_df=3, vect__ngram_range=(1, 1), score=0.8316937761760982, total=  47.1s\n",
      "[CV] vect__analyzer=<function split_into_stems at 0x000002076DC30AE8>, vect__max_df=1.0, vect__min_df=3, vect__ngram_range=(1, 1) \n",
      "[CV]  vect__analyzer=<function split_into_stems at 0x000002076DC30AE8>, vect__max_df=1.0, vect__min_df=3, vect__ngram_range=(1, 1), score=0.8260446089412682, total=  54.7s\n",
      "[CV] vect__analyzer=<function split_into_stems at 0x000002076DC30AE8>, vect__max_df=1.0, vect__min_df=3, vect__ngram_range=(1, 2) \n",
      "[CV]  vect__analyzer=<function split_into_stems at 0x000002076DC30AE8>, vect__max_df=1.0, vect__min_df=3, vect__ngram_range=(1, 2), score=0.8307767226686146, total= 1.0min\n",
      "[CV] vect__analyzer=<function split_into_stems at 0x000002076DC30AE8>, vect__max_df=1.0, vect__min_df=3, vect__ngram_range=(1, 2) \n",
      "[CV]  vect__analyzer=<function split_into_stems at 0x000002076DC30AE8>, vect__max_df=1.0, vect__min_df=3, vect__ngram_range=(1, 2), score=0.8316937761760982, total=  49.0s\n",
      "[CV] vect__analyzer=<function split_into_stems at 0x000002076DC30AE8>, vect__max_df=1.0, vect__min_df=3, vect__ngram_range=(1, 2) \n",
      "[CV]  vect__analyzer=<function split_into_stems at 0x000002076DC30AE8>, vect__max_df=1.0, vect__min_df=3, vect__ngram_range=(1, 2), score=0.8260446089412682, total=  46.7s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Done  72 out of  72 | elapsed: 89.9min finished\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "GridSearchCV(cv=3, error_score='raise',\n",
       "       estimator=Pipeline(memory=None,\n",
       "     steps=[('vect', CountVectorizer(analyzer='word', binary=False, decode_error='strict',\n",
       "        dtype=<class 'numpy.int64'>, encoding='utf-8', input='content',\n",
       "        lowercase=True, max_df=1.0, max_features=None, min_df=1,\n",
       "        ngram_range=(1, 1), preprocessor=None, stop_words=None,\n",
       "        strip_accents=None, token_pattern='(?u)\\\\b\\\\w\\\\w+\\\\b',\n",
       "        tokenizer=None, vocabulary=None)), ('clf', MultinomialNB(alpha=1.0, class_prior=None, fit_prior=True))]),\n",
       "       fit_params=None, iid=True, n_jobs=1,\n",
       "       param_grid={'vect__analyzer': (<function split_into_lemmas at 0x000002077A15F7B8>, <function split_into_stems at 0x000002076DC30AE8>), 'vect__max_df': (0.75, 1.0), 'vect__min_df': (1, 2, 3), 'vect__ngram_range': ((1, 1), (1, 2))},\n",
       "       pre_dispatch='2*n_jobs', refit=True, return_train_score='warn',\n",
       "       scoring=None, verbose=10)"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "grid_search = GridSearchCV(estimator=pipeline,\n",
    "                           param_grid=parameters,\n",
    "                           cv=3,\n",
    "                           verbose=10)\n",
    "\n",
    "grid_search.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Print out the results of my gridsearch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best score: 0.836\n",
      "Best parameters set:\n",
      "\tvect__analyzer: <function split_into_stems at 0x000002076DC30AE8>\n",
      "\tvect__max_df: 1.0\n",
      "\tvect__min_df: 1\n",
      "\tvect__ngram_range: (1, 1)\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.81      0.90      0.85     10258\n",
      "          1       0.89      0.78      0.83     10277\n",
      "\n",
      "avg / total       0.85      0.84      0.84     20535\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(\"Best score: %0.3f\" % grid_search.best_score_)\n",
    "print(\"Best parameters set:\")\n",
    "best_parameters = grid_search.best_estimator_.get_params()\n",
    "for param_name in sorted(parameters.keys()):\n",
    "    print(\"\\t%s: %r\" % (param_name, best_parameters[param_name]))\n",
    "print(metrics.classification_report(y_test, grid_search.predict(X_test)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
