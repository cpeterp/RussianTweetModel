{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package stopwords to\n",
      "[nltk_data]     C:\\Users\\599701\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import scipy as sp\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from pprint import pprint\n",
    "from time import time\n",
    "from textblob import TextBlob, Word\n",
    "\n",
    "import logging\n",
    "from nltk.stem.snowball import SnowballStemmer\n",
    "from nltk.corpus import stopwords\n",
    "import nltk\n",
    "nltk.download('stopwords')\n",
    "\n",
    "from sklearn.model_selection import train_test_split as tts\n",
    "from sklearn.feature_extraction.text import CountVectorizer, TfidfVectorizer\n",
    "from sklearn.naive_bayes import MultinomialNB         # Naive Bayes\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn import metrics\n",
    "from sklearn.utils import resample\n",
    "\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.pipeline import Pipeline\n",
    "\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "tweet_data = pd.read_csv(\"./datasets/combined_data.csv\", sep=\";\", \n",
    "                         dtype={'tweet_id':str, 'author_id':str, 'publish_date':str, \n",
    "                                'content':str, 'link_url':str, 'account_category':str, \n",
    "                                'author':str, 'account_type':str})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "tweet_data = pd.get_dummies(tweet_data, columns=['account_type', 'account_category'], drop_first=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_Troll = tweet_data[tweet_data.account_category_Troll == 1]\n",
    "df_Pol = tweet_data[tweet_data.account_category_Politician == 1]\n",
    "df_News = tweet_data[tweet_data.account_category_US_News == 1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(41069, 18)\n",
      "(41066, 18)\n",
      "(41069, 18)\n"
     ]
    }
   ],
   "source": [
    "print(df_Troll.shape)\n",
    "print(df_Pol.shape)\n",
    "print(df_News.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Some Different testing sets\n",
    "df_Trolls_News = pd.concat([df_Troll, df_News])\n",
    "df_Trolls_Pol = pd.concat([df_Troll, df_Pol])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We'll start by comparing trolls and news outlets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = df_Trolls_News['content']\n",
    "y = df_Trolls_News['account_category_Troll']\n",
    "X_train, X_test, y_train, y_test = tts(X, y, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define a function that accepts a vectorizer and calculates the accuracy.\n",
    "def tokenize_test(vect):\n",
    "    X_train_dtm = vect.fit_transform(X_train)\n",
    "    print(('Features: ', X_train_dtm.shape[1]))\n",
    "    X_test_dtm = vect.transform(X_test)\n",
    "    nb = MultinomialNB()\n",
    "    nb.fit(X_train_dtm, y_train)\n",
    "    y_pred_class = nb.predict(X_test_dtm)\n",
    "    #print(('Accuracy: ', metrics.accuracy_score(y_test, y_pred_class)))\n",
    "    print(metrics.classification_report(y_test, y_pred_class))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "('Features: ', 88822)\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.83      0.88      0.85     10258\n",
      "          1       0.87      0.82      0.84     10277\n",
      "\n",
      "avg / total       0.85      0.85      0.85     20535\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# First Try\n",
    "vect = CountVectorizer(ngram_range=(1, 2), stop_words=\"english\", min_df=2)\n",
    "tokenize_test(vect)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define a function that accepts text and returns a list of stems.\n",
    "stemmer = SnowballStemmer('english')\n",
    "def split_into_stems(text):\n",
    "    text = str(text).lower()\n",
    "    words = TextBlob(text).words\n",
    "    return [stemmer.stem(word) for word in words]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "('Features: ', 20761)\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.82      0.87      0.84     10258\n",
      "          1       0.86      0.80      0.83     10277\n",
      "\n",
      "avg / total       0.84      0.84      0.84     20535\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Use split_into_stems as the feature extraction function (Warning: SLOW!).\n",
    "vect = CountVectorizer(analyzer=split_into_stems, decode_error='replace', ngram_range=(1,2), stop_words=\"english\", min_df=2, max_df=.75)\n",
    "tokenize_test(vect)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define a function that accepts text and returns a list of lemmas.\n",
    "def split_into_lemmas(text):\n",
    "    text = str(text).lower()\n",
    "    words = TextBlob(text).words\n",
    "    return [word.lemmatize() for word in words]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "('Features: ', 25090)\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.81      0.87      0.84     10258\n",
      "          1       0.86      0.79      0.83     10277\n",
      "\n",
      "avg / total       0.84      0.83      0.83     20535\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Use split_into_lemmas as the feature extraction function (Warning: SLOW!).\n",
    "vect = CountVectorizer(analyzer=split_into_lemmas, decode_error='replace', stop_words=\"english\", min_df=2)\n",
    "tokenize_test(vect)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train_dtm = vect.fit_transform(X_train)\n",
    "X_test_dtm = vect.transform(X_test)\n",
    "nb = MultinomialNB()\n",
    "nb.fit(X_train_dtm, y_train)\n",
    "y_pred_class = nb.predict(X_test_dtm)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.81      0.87      0.84     10258\n",
      "          1       0.86      0.79      0.83     10277\n",
      "\n",
      "avg / total       0.84      0.83      0.83     20535\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(metrics.classification_report(y_test, y_pred_class))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "# neg_class_prob_sorted = nb.feature_log_prob_[0, :].argsort()\n",
    "# pos_class_prob_sorted = nb.feature_log_prob_[1, :].argsort()\n",
    "\n",
    "# print(np.take(vect.get_feature_names(), neg_class_prob_sorted[:10]))\n",
    "# print(np.take(vect.get_feature_names(), pos_class_prob_sorted[:10]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "# df_Trolls_News.loc[df_Trolls_News['content'].str.contains('coe'), ['content', 'account_category_Troll']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "Wrong number of items passed 2, placement implies 1",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "\u001b[1;32m~\\AppData\\Local\\Continuum\\anaconda3\\lib\\site-packages\\pandas\\core\\indexes\\base.py\u001b[0m in \u001b[0;36mget_loc\u001b[1;34m(self, key, method, tolerance)\u001b[0m\n\u001b[0;32m   3062\u001b[0m             \u001b[1;32mtry\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 3063\u001b[1;33m                 \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_engine\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mget_loc\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   3064\u001b[0m             \u001b[1;32mexcept\u001b[0m \u001b[0mKeyError\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mpandas\\_libs\\index.pyx\u001b[0m in \u001b[0;36mpandas._libs.index.IndexEngine.get_loc\u001b[1;34m()\u001b[0m\n",
      "\u001b[1;32mpandas\\_libs\\index.pyx\u001b[0m in \u001b[0;36mpandas._libs.index.IndexEngine.get_loc\u001b[1;34m()\u001b[0m\n",
      "\u001b[1;32mpandas\\_libs\\hashtable_class_helper.pxi\u001b[0m in \u001b[0;36mpandas._libs.hashtable.PyObjectHashTable.get_item\u001b[1;34m()\u001b[0m\n",
      "\u001b[1;32mpandas\\_libs\\hashtable_class_helper.pxi\u001b[0m in \u001b[0;36mpandas._libs.hashtable.PyObjectHashTable.get_item\u001b[1;34m()\u001b[0m\n",
      "\u001b[1;31mKeyError\u001b[0m: 'proba'",
      "\nDuring handling of the above exception, another exception occurred:\n",
      "\u001b[1;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "\u001b[1;32m~\\AppData\\Local\\Continuum\\anaconda3\\lib\\site-packages\\pandas\\core\\internals.py\u001b[0m in \u001b[0;36mset\u001b[1;34m(self, item, value, check)\u001b[0m\n\u001b[0;32m   4242\u001b[0m         \u001b[1;32mtry\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 4243\u001b[1;33m             \u001b[0mloc\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mitems\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mget_loc\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mitem\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   4244\u001b[0m         \u001b[1;32mexcept\u001b[0m \u001b[0mKeyError\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\AppData\\Local\\Continuum\\anaconda3\\lib\\site-packages\\pandas\\core\\indexes\\base.py\u001b[0m in \u001b[0;36mget_loc\u001b[1;34m(self, key, method, tolerance)\u001b[0m\n\u001b[0;32m   3064\u001b[0m             \u001b[1;32mexcept\u001b[0m \u001b[0mKeyError\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 3065\u001b[1;33m                 \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_engine\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mget_loc\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_maybe_cast_indexer\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   3066\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mpandas\\_libs\\index.pyx\u001b[0m in \u001b[0;36mpandas._libs.index.IndexEngine.get_loc\u001b[1;34m()\u001b[0m\n",
      "\u001b[1;32mpandas\\_libs\\index.pyx\u001b[0m in \u001b[0;36mpandas._libs.index.IndexEngine.get_loc\u001b[1;34m()\u001b[0m\n",
      "\u001b[1;32mpandas\\_libs\\hashtable_class_helper.pxi\u001b[0m in \u001b[0;36mpandas._libs.hashtable.PyObjectHashTable.get_item\u001b[1;34m()\u001b[0m\n",
      "\u001b[1;32mpandas\\_libs\\hashtable_class_helper.pxi\u001b[0m in \u001b[0;36mpandas._libs.hashtable.PyObjectHashTable.get_item\u001b[1;34m()\u001b[0m\n",
      "\u001b[1;31mKeyError\u001b[0m: 'proba'",
      "\nDuring handling of the above exception, another exception occurred:\n",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-38-5360d4c09266>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m()\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[0mdf_dtm\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mvect\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtransform\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdf_Trolls_News\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'content'\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 2\u001b[1;33m \u001b[0mdf_Trolls_News\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'proba'\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mnb\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpredict_proba\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdf_dtm\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;32m~\\AppData\\Local\\Continuum\\anaconda3\\lib\\site-packages\\pandas\\core\\frame.py\u001b[0m in \u001b[0;36m__setitem__\u001b[1;34m(self, key, value)\u001b[0m\n\u001b[0;32m   3114\u001b[0m         \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   3115\u001b[0m             \u001b[1;31m# set column\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 3116\u001b[1;33m             \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_set_item\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mvalue\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   3117\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   3118\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0m_setitem_slice\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mkey\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mvalue\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\AppData\\Local\\Continuum\\anaconda3\\lib\\site-packages\\pandas\\core\\frame.py\u001b[0m in \u001b[0;36m_set_item\u001b[1;34m(self, key, value)\u001b[0m\n\u001b[0;32m   3190\u001b[0m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_ensure_valid_index\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mvalue\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   3191\u001b[0m         \u001b[0mvalue\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_sanitize_column\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mvalue\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 3192\u001b[1;33m         \u001b[0mNDFrame\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_set_item\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mkey\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mvalue\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   3193\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   3194\u001b[0m         \u001b[1;31m# check if we are modifying a copy\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\AppData\\Local\\Continuum\\anaconda3\\lib\\site-packages\\pandas\\core\\generic.py\u001b[0m in \u001b[0;36m_set_item\u001b[1;34m(self, key, value)\u001b[0m\n\u001b[0;32m   2595\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   2596\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0m_set_item\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mkey\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mvalue\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 2597\u001b[1;33m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_data\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mset\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mvalue\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   2598\u001b[0m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_clear_item_cache\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   2599\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\AppData\\Local\\Continuum\\anaconda3\\lib\\site-packages\\pandas\\core\\internals.py\u001b[0m in \u001b[0;36mset\u001b[1;34m(self, item, value, check)\u001b[0m\n\u001b[0;32m   4244\u001b[0m         \u001b[1;32mexcept\u001b[0m \u001b[0mKeyError\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   4245\u001b[0m             \u001b[1;31m# This item wasn't present, just insert at end\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 4246\u001b[1;33m             \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0minsert\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mlen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mitems\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mitem\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mvalue\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   4247\u001b[0m             \u001b[1;32mreturn\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   4248\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\AppData\\Local\\Continuum\\anaconda3\\lib\\site-packages\\pandas\\core\\internals.py\u001b[0m in \u001b[0;36minsert\u001b[1;34m(self, loc, item, value, allow_duplicates)\u001b[0m\n\u001b[0;32m   4345\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   4346\u001b[0m         block = make_block(values=value, ndim=self.ndim,\n\u001b[1;32m-> 4347\u001b[1;33m                            placement=slice(loc, loc + 1))\n\u001b[0m\u001b[0;32m   4348\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   4349\u001b[0m         \u001b[1;32mfor\u001b[0m \u001b[0mblkno\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcount\u001b[0m \u001b[1;32min\u001b[0m \u001b[0m_fast_count_smallints\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_blknos\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mloc\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\AppData\\Local\\Continuum\\anaconda3\\lib\\site-packages\\pandas\\core\\internals.py\u001b[0m in \u001b[0;36mmake_block\u001b[1;34m(values, placement, klass, ndim, dtype, fastpath)\u001b[0m\n\u001b[0;32m   3203\u001b[0m                      placement=placement, dtype=dtype)\n\u001b[0;32m   3204\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 3205\u001b[1;33m     \u001b[1;32mreturn\u001b[0m \u001b[0mklass\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mvalues\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mndim\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mndim\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mplacement\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mplacement\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   3206\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   3207\u001b[0m \u001b[1;31m# TODO: flexible with index=None and/or items=None\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\AppData\\Local\\Continuum\\anaconda3\\lib\\site-packages\\pandas\\core\\internals.py\u001b[0m in \u001b[0;36m__init__\u001b[1;34m(self, values, placement, ndim)\u001b[0m\n\u001b[0;32m    123\u001b[0m             raise ValueError(\n\u001b[0;32m    124\u001b[0m                 \u001b[1;34m'Wrong number of items passed {val}, placement implies '\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 125\u001b[1;33m                 '{mgr}'.format(val=len(self.values), mgr=len(self.mgr_locs)))\n\u001b[0m\u001b[0;32m    126\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    127\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0m_check_ndim\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mvalues\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mndim\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mValueError\u001b[0m: Wrong number of items passed 2, placement implies 1"
     ]
    }
   ],
   "source": [
    "df_dtm = vect.transform(df_Trolls_News['content'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [],
   "source": [
    "proba = nb.predict_proba(df_dtm)\n",
    "df_Trolls_News['proba_troll'] = proba[:,1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>author</th>\n",
       "      <th>content</th>\n",
       "      <th>proba_troll</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>169463</th>\n",
       "      <td>FoxNews</td>\n",
       "      <td>Huckabee: \"The greatest single characteristic ...</td>\n",
       "      <td>1.000000e+00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>155992</th>\n",
       "      <td>FoxNews</td>\n",
       "      <td>.@POTUS on Democrats: \"I don't think they want...</td>\n",
       "      <td>1.000000e+00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>167543</th>\n",
       "      <td>nytimes</td>\n",
       "      <td>RT @jennydeluxe: \"Being black in the age of wo...</td>\n",
       "      <td>1.000000e+00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>148629</th>\n",
       "      <td>FoxNews</td>\n",
       "      <td>.@POTUS to U.S. servicemembers: \"We support yo...</td>\n",
       "      <td>9.999999e-01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>157242</th>\n",
       "      <td>USATODAY</td>\n",
       "      <td>\"All I really want to do is tell you that I'm ...</td>\n",
       "      <td>9.999999e-01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>148739</th>\n",
       "      <td>CNN</td>\n",
       "      <td>Imagine \"you're an NBA coach...and you're gonn...</td>\n",
       "      <td>9.999995e-01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>143938</th>\n",
       "      <td>FoxNews</td>\n",
       "      <td>.@TGowdySC: \"Jim Comey said, 'I don't do sneak...</td>\n",
       "      <td>9.999994e-01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>143921</th>\n",
       "      <td>FoxNews</td>\n",
       "      <td>.@TGowdySC: \"Jim Comey said, 'I don't do sneak...</td>\n",
       "      <td>9.999994e-01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>170873</th>\n",
       "      <td>FoxNews</td>\n",
       "      <td>.@POTUS: \"May God bless you. May God bless our...</td>\n",
       "      <td>9.999992e-01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>148784</th>\n",
       "      <td>CNN</td>\n",
       "      <td>\"Sometimes I don't know what this world has co...</td>\n",
       "      <td>9.999992e-01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>158028</th>\n",
       "      <td>USATODAY</td>\n",
       "      <td>\"What I long for is to reunite with them. I be...</td>\n",
       "      <td>9.999989e-01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>142658</th>\n",
       "      <td>nypost</td>\n",
       "      <td>“If you’re out there listening to me, I’m call...</td>\n",
       "      <td>9.999989e-01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>134813</th>\n",
       "      <td>FoxNews</td>\n",
       "      <td>@kayleighmcenany: \"If you want to put up @Eric...</td>\n",
       "      <td>9.999988e-01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>139722</th>\n",
       "      <td>FoxNews</td>\n",
       "      <td>.@DiamondandSilk: \"I'm not for taking away any...</td>\n",
       "      <td>9.999982e-01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>147072</th>\n",
       "      <td>HuffPost</td>\n",
       "      <td>RT @lee_moran: “Trump really opens my mind for...</td>\n",
       "      <td>9.999969e-01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>155960</th>\n",
       "      <td>FoxNews</td>\n",
       "      <td>.@GovMikeHuckabee: \"This is no longer about @P...</td>\n",
       "      <td>9.999964e-01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>155964</th>\n",
       "      <td>FoxNews</td>\n",
       "      <td>.@GovMikeHuckabee: \"This is no longer about @P...</td>\n",
       "      <td>9.999964e-01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>154916</th>\n",
       "      <td>FoxNews</td>\n",
       "      <td>.@realDonaldTrump: \"Anyone who knows me, knows...</td>\n",
       "      <td>9.999960e-01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>170830</th>\n",
       "      <td>FoxNews</td>\n",
       "      <td>.@POTUS: \"We salute you, we salute your servic...</td>\n",
       "      <td>9.999954e-01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>157712</th>\n",
       "      <td>nypost</td>\n",
       "      <td>“We assumed that he liked the area and just li...</td>\n",
       "      <td>9.999950e-01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>154653</th>\n",
       "      <td>politico</td>\n",
       "      <td>Trump: \"Anyone who knows me knows these words ...</td>\n",
       "      <td>9.999945e-01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>156005</th>\n",
       "      <td>FoxNews</td>\n",
       "      <td>.@POTUS: \"There was zero movement from @TheDem...</td>\n",
       "      <td>9.999932e-01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>148643</th>\n",
       "      <td>CNN</td>\n",
       "      <td>Happy #PiDay\\r\\r\\n\\r\\r\\nIf you really want to ...</td>\n",
       "      <td>9.999929e-01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>158218</th>\n",
       "      <td>nypost</td>\n",
       "      <td>\"It's gotten to the point now where it's just ...</td>\n",
       "      <td>9.999909e-01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>160667</th>\n",
       "      <td>HuffPost</td>\n",
       "      <td>“I have been hearing Marvel male superheroes c...</td>\n",
       "      <td>9.999903e-01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>171721</th>\n",
       "      <td>nytimes</td>\n",
       "      <td>RT @carlzimmer: For my @nytimes column today I...</td>\n",
       "      <td>9.999887e-01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>148631</th>\n",
       "      <td>FoxNews</td>\n",
       "      <td>.@POTUS to @USMC: \"Our administration is stack...</td>\n",
       "      <td>9.999881e-01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>148607</th>\n",
       "      <td>FoxNews</td>\n",
       "      <td>.@POTUS to @USMC: \"Our administration is stack...</td>\n",
       "      <td>9.999881e-01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>139686</th>\n",
       "      <td>FoxNews</td>\n",
       "      <td>.@KellyannePolls to @HillaryClinton: \"Let me t...</td>\n",
       "      <td>9.999856e-01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>147769</th>\n",
       "      <td>nytimes</td>\n",
       "      <td>“Remember to look up at the stars and not down...</td>\n",
       "      <td>9.999851e-01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>137963</th>\n",
       "      <td>NPR</td>\n",
       "      <td>Democrat Conor Lamb appears to have won the sp...</td>\n",
       "      <td>5.222993e-12</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>147782</th>\n",
       "      <td>nytimes</td>\n",
       "      <td>United Airlines apologized after a dog died on...</td>\n",
       "      <td>5.125908e-12</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>147257</th>\n",
       "      <td>ABC</td>\n",
       "      <td>LATEST: Russian Embassy in UK responds to Brit...</td>\n",
       "      <td>4.754654e-12</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>132553</th>\n",
       "      <td>ABC</td>\n",
       "      <td>JUST IN: Geoffrey Berman, U.S. Attorney for So...</td>\n",
       "      <td>3.682799e-12</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>132507</th>\n",
       "      <td>chicagotribune</td>\n",
       "      <td>Yulia Skripal, daughter of ex-Russian spy Serg...</td>\n",
       "      <td>2.990771e-12</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>148752</th>\n",
       "      <td>CNN</td>\n",
       "      <td>British Physicist Stephen Hawking has died, ac...</td>\n",
       "      <td>2.878063e-12</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>136099</th>\n",
       "      <td>HuffPost</td>\n",
       "      <td>PyeongChang built itself a brand-new $109 mill...</td>\n",
       "      <td>2.819105e-12</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>148766</th>\n",
       "      <td>CNN</td>\n",
       "      <td>British physicist Stephen Hawking has died at ...</td>\n",
       "      <td>2.789064e-12</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>148785</th>\n",
       "      <td>CNN</td>\n",
       "      <td>British physicist Stephen Hawking has died at ...</td>\n",
       "      <td>2.789064e-12</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>132505</th>\n",
       "      <td>chicagotribune</td>\n",
       "      <td>President Xi Jinping promised Tuesday to cut C...</td>\n",
       "      <td>2.313831e-12</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>159298</th>\n",
       "      <td>FoxNews</td>\n",
       "      <td>U.S. service members with the Defense POW/MIA ...</td>\n",
       "      <td>2.086343e-12</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>159383</th>\n",
       "      <td>FoxNews</td>\n",
       "      <td>U.S. service members with the Defense POW/MIA ...</td>\n",
       "      <td>2.086343e-12</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>133306</th>\n",
       "      <td>Reuters</td>\n",
       "      <td>Tuesday Morning Briefing: \\r\\r\\n- Zuckerberg t...</td>\n",
       "      <td>1.652698e-12</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>139218</th>\n",
       "      <td>WSJ</td>\n",
       "      <td>Students from Marjory Stoneman Douglas High Sc...</td>\n",
       "      <td>8.290688e-13</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>147247</th>\n",
       "      <td>ABC</td>\n",
       "      <td>NEW: Pres. Trump picks conservative economic c...</td>\n",
       "      <td>7.829416e-13</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>138627</th>\n",
       "      <td>ABC</td>\n",
       "      <td>Students at Stoneman Douglas High School in Pa...</td>\n",
       "      <td>6.624178e-13</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>133771</th>\n",
       "      <td>CNN</td>\n",
       "      <td>JUST IN: Yulia Skripal, daughter of Russian ex...</td>\n",
       "      <td>5.950150e-13</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>133440</th>\n",
       "      <td>Reuters</td>\n",
       "      <td>Stock rally as Chinese President Xi Jinping pr...</td>\n",
       "      <td>4.547639e-13</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>133437</th>\n",
       "      <td>Reuters</td>\n",
       "      <td>Amid rising trade tensions between China and t...</td>\n",
       "      <td>4.410100e-13</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>134699</th>\n",
       "      <td>CNN</td>\n",
       "      <td>South Korean President Moon Jae-in welcomed se...</td>\n",
       "      <td>3.947579e-13</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>147288</th>\n",
       "      <td>ABC</td>\n",
       "      <td>MORE: The UK will expel 23 Russian diplomats f...</td>\n",
       "      <td>3.897301e-13</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>146590</th>\n",
       "      <td>USATODAY</td>\n",
       "      <td>Students at Marjory Stoneman Douglas High Scho...</td>\n",
       "      <td>2.989869e-13</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>169649</th>\n",
       "      <td>CNN</td>\n",
       "      <td>British authorities examining the poisoning of...</td>\n",
       "      <td>2.434730e-13</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>169584</th>\n",
       "      <td>CNN</td>\n",
       "      <td>British authorities examining the poisoning of...</td>\n",
       "      <td>2.434730e-13</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>132540</th>\n",
       "      <td>ABC</td>\n",
       "      <td>JUST IN: Yulia Skripal, daughter of former Rus...</td>\n",
       "      <td>1.261528e-13</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>131925</th>\n",
       "      <td>NPR</td>\n",
       "      <td>China's President Xi Jinping says his country ...</td>\n",
       "      <td>1.227897e-13</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>147259</th>\n",
       "      <td>ABC</td>\n",
       "      <td>Huge makeshift memorial to Parkland shooting v...</td>\n",
       "      <td>1.149377e-13</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>135104</th>\n",
       "      <td>Reuters</td>\n",
       "      <td>North Korean leader Kim Jong Un invites South ...</td>\n",
       "      <td>3.332891e-14</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>147265</th>\n",
       "      <td>ABC</td>\n",
       "      <td>Students at Marjory Stoneman Douglas High Scho...</td>\n",
       "      <td>1.333167e-14</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>147799</th>\n",
       "      <td>politico</td>\n",
       "      <td>Larry Kudlow has been widely seen as a leading...</td>\n",
       "      <td>6.359487e-16</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>41069 rows × 3 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                author                                            content  \\\n",
       "169463         FoxNews  Huckabee: \"The greatest single characteristic ...   \n",
       "155992         FoxNews  .@POTUS on Democrats: \"I don't think they want...   \n",
       "167543         nytimes  RT @jennydeluxe: \"Being black in the age of wo...   \n",
       "148629         FoxNews  .@POTUS to U.S. servicemembers: \"We support yo...   \n",
       "157242        USATODAY  \"All I really want to do is tell you that I'm ...   \n",
       "148739             CNN  Imagine \"you're an NBA coach...and you're gonn...   \n",
       "143938         FoxNews  .@TGowdySC: \"Jim Comey said, 'I don't do sneak...   \n",
       "143921         FoxNews  .@TGowdySC: \"Jim Comey said, 'I don't do sneak...   \n",
       "170873         FoxNews  .@POTUS: \"May God bless you. May God bless our...   \n",
       "148784             CNN  \"Sometimes I don't know what this world has co...   \n",
       "158028        USATODAY  \"What I long for is to reunite with them. I be...   \n",
       "142658          nypost  “If you’re out there listening to me, I’m call...   \n",
       "134813         FoxNews  @kayleighmcenany: \"If you want to put up @Eric...   \n",
       "139722         FoxNews  .@DiamondandSilk: \"I'm not for taking away any...   \n",
       "147072        HuffPost  RT @lee_moran: “Trump really opens my mind for...   \n",
       "155960         FoxNews  .@GovMikeHuckabee: \"This is no longer about @P...   \n",
       "155964         FoxNews  .@GovMikeHuckabee: \"This is no longer about @P...   \n",
       "154916         FoxNews  .@realDonaldTrump: \"Anyone who knows me, knows...   \n",
       "170830         FoxNews  .@POTUS: \"We salute you, we salute your servic...   \n",
       "157712          nypost  “We assumed that he liked the area and just li...   \n",
       "154653        politico  Trump: \"Anyone who knows me knows these words ...   \n",
       "156005         FoxNews  .@POTUS: \"There was zero movement from @TheDem...   \n",
       "148643             CNN  Happy #PiDay\\r\\r\\n\\r\\r\\nIf you really want to ...   \n",
       "158218          nypost  \"It's gotten to the point now where it's just ...   \n",
       "160667        HuffPost  “I have been hearing Marvel male superheroes c...   \n",
       "171721         nytimes  RT @carlzimmer: For my @nytimes column today I...   \n",
       "148631         FoxNews  .@POTUS to @USMC: \"Our administration is stack...   \n",
       "148607         FoxNews  .@POTUS to @USMC: \"Our administration is stack...   \n",
       "139686         FoxNews  .@KellyannePolls to @HillaryClinton: \"Let me t...   \n",
       "147769         nytimes  “Remember to look up at the stars and not down...   \n",
       "...                ...                                                ...   \n",
       "137963             NPR  Democrat Conor Lamb appears to have won the sp...   \n",
       "147782         nytimes  United Airlines apologized after a dog died on...   \n",
       "147257             ABC  LATEST: Russian Embassy in UK responds to Brit...   \n",
       "132553             ABC  JUST IN: Geoffrey Berman, U.S. Attorney for So...   \n",
       "132507  chicagotribune  Yulia Skripal, daughter of ex-Russian spy Serg...   \n",
       "148752             CNN  British Physicist Stephen Hawking has died, ac...   \n",
       "136099        HuffPost  PyeongChang built itself a brand-new $109 mill...   \n",
       "148766             CNN  British physicist Stephen Hawking has died at ...   \n",
       "148785             CNN  British physicist Stephen Hawking has died at ...   \n",
       "132505  chicagotribune  President Xi Jinping promised Tuesday to cut C...   \n",
       "159298         FoxNews  U.S. service members with the Defense POW/MIA ...   \n",
       "159383         FoxNews  U.S. service members with the Defense POW/MIA ...   \n",
       "133306         Reuters  Tuesday Morning Briefing: \\r\\r\\n- Zuckerberg t...   \n",
       "139218             WSJ  Students from Marjory Stoneman Douglas High Sc...   \n",
       "147247             ABC  NEW: Pres. Trump picks conservative economic c...   \n",
       "138627             ABC  Students at Stoneman Douglas High School in Pa...   \n",
       "133771             CNN  JUST IN: Yulia Skripal, daughter of Russian ex...   \n",
       "133440         Reuters  Stock rally as Chinese President Xi Jinping pr...   \n",
       "133437         Reuters  Amid rising trade tensions between China and t...   \n",
       "134699             CNN  South Korean President Moon Jae-in welcomed se...   \n",
       "147288             ABC  MORE: The UK will expel 23 Russian diplomats f...   \n",
       "146590        USATODAY  Students at Marjory Stoneman Douglas High Scho...   \n",
       "169649             CNN  British authorities examining the poisoning of...   \n",
       "169584             CNN  British authorities examining the poisoning of...   \n",
       "132540             ABC  JUST IN: Yulia Skripal, daughter of former Rus...   \n",
       "131925             NPR  China's President Xi Jinping says his country ...   \n",
       "147259             ABC  Huge makeshift memorial to Parkland shooting v...   \n",
       "135104         Reuters  North Korean leader Kim Jong Un invites South ...   \n",
       "147265             ABC  Students at Marjory Stoneman Douglas High Scho...   \n",
       "147799        politico  Larry Kudlow has been widely seen as a leading...   \n",
       "\n",
       "         proba_troll  \n",
       "169463  1.000000e+00  \n",
       "155992  1.000000e+00  \n",
       "167543  1.000000e+00  \n",
       "148629  9.999999e-01  \n",
       "157242  9.999999e-01  \n",
       "148739  9.999995e-01  \n",
       "143938  9.999994e-01  \n",
       "143921  9.999994e-01  \n",
       "170873  9.999992e-01  \n",
       "148784  9.999992e-01  \n",
       "158028  9.999989e-01  \n",
       "142658  9.999989e-01  \n",
       "134813  9.999988e-01  \n",
       "139722  9.999982e-01  \n",
       "147072  9.999969e-01  \n",
       "155960  9.999964e-01  \n",
       "155964  9.999964e-01  \n",
       "154916  9.999960e-01  \n",
       "170830  9.999954e-01  \n",
       "157712  9.999950e-01  \n",
       "154653  9.999945e-01  \n",
       "156005  9.999932e-01  \n",
       "148643  9.999929e-01  \n",
       "158218  9.999909e-01  \n",
       "160667  9.999903e-01  \n",
       "171721  9.999887e-01  \n",
       "148631  9.999881e-01  \n",
       "148607  9.999881e-01  \n",
       "139686  9.999856e-01  \n",
       "147769  9.999851e-01  \n",
       "...              ...  \n",
       "137963  5.222993e-12  \n",
       "147782  5.125908e-12  \n",
       "147257  4.754654e-12  \n",
       "132553  3.682799e-12  \n",
       "132507  2.990771e-12  \n",
       "148752  2.878063e-12  \n",
       "136099  2.819105e-12  \n",
       "148766  2.789064e-12  \n",
       "148785  2.789064e-12  \n",
       "132505  2.313831e-12  \n",
       "159298  2.086343e-12  \n",
       "159383  2.086343e-12  \n",
       "133306  1.652698e-12  \n",
       "139218  8.290688e-13  \n",
       "147247  7.829416e-13  \n",
       "138627  6.624178e-13  \n",
       "133771  5.950150e-13  \n",
       "133440  4.547639e-13  \n",
       "133437  4.410100e-13  \n",
       "134699  3.947579e-13  \n",
       "147288  3.897301e-13  \n",
       "146590  2.989869e-13  \n",
       "169649  2.434730e-13  \n",
       "169584  2.434730e-13  \n",
       "132540  1.261528e-13  \n",
       "131925  1.227897e-13  \n",
       "147259  1.149377e-13  \n",
       "135104  3.332891e-14  \n",
       "147265  1.333167e-14  \n",
       "147799  6.359487e-16  \n",
       "\n",
       "[41069 rows x 3 columns]"
      ]
     },
     "execution_count": 61,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_Trolls_News.loc[df_Trolls_News.account_category_Troll==0].sort_values(by='proba_troll', ascending=False)[['author', 'content', 'proba_troll']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "vect = CountVectorizer(ngram_range=(1, 2), stop_words=\"english\")\n",
    "tokenize_test(vect)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pipeline = Pipeline([\n",
    "    ('vect', CountVectorizer()),\n",
    "    ('clf', MultinomialNB()),])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "parameters = {\n",
    "    'vect__max_df': (0.5, 0.75, 1.0),\n",
    "    'vect__min_df': (1, 2, 3),\n",
    "    #'vect__max_features': (None, 5000, 10000, 50000),\n",
    "    'vect__ngram_range': ((1, 1), (1, 2)),  # unigrams or bigrams\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "grid_search = GridSearchCV(estimator=pipeline,\n",
    "                           param_grid=parameters,\n",
    "                           cv=3,\n",
    "                           verbose=1)\n",
    "\n",
    "grid_search.fit(X_train.values.tolist(), y=y_train.values.tolist())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Best score: %0.3f\" % grid_search.best_score_)\n",
    "print(\"Best parameters set:\")\n",
    "best_parameters = grid_search.best_estimator_.get_params()\n",
    "for param_name in sorted(parameters.keys()):\n",
    "    print(\"\\t%s: %r\" % (param_name, best_parameters[param_name]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = tweet_sample['content']\n",
    "y = tweet_sample['account_category_Troll']\n",
    "X_train, X_test, y_train, y_test = tts(X, y, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "vect = CountVectorizer(max_df=.75, ngram_range=(1, 2), stop_words=\"english\", min_df=2)\n",
    "tokenize_test(vect)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = tweet_sample['content']\n",
    "y = tweet_sample['account_type_Right']\n",
    "X_train, X_test, y_train, y_test = tts(X, y, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "vect = CountVectorizer(max_df=.75, ngram_range=(1, 2), stop_words=\"english\", min_df=2)\n",
    "tokenize_test(vect)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.linear_model import LogisticRegression\n",
    "# Define a function that accepts a vectorizer and calculates the accuracy.\n",
    "def tokenize_test_log(vect):\n",
    "    X_train_dtm = vect.fit_transform(X_train)\n",
    "    print(('Features: ', X_train_dtm.shape[1]))\n",
    "    X_test_dtm = vect.transform(X_test)\n",
    "    log = LogisticRegression()\n",
    "    log.fit(X_train_dtm, y_train)\n",
    "    y_pred_class = log.predict(X_test_dtm)\n",
    "    #print(('Accuracy: ', metrics.accuracy_score(y_test, y_pred_class)))\n",
    "    print(metrics.classification_report(y_test, y_pred_class))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "vect = CountVectorizer(max_df=.75, ngram_range=(1, 2), stop_words=\"english\", min_df=2)\n",
    "tokenize_test_log(vect)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.svm import SVC\n",
    "\n",
    "def tokenize_test_svc(vect):\n",
    "    X_train_dtm = vect.fit_transform(X_train)\n",
    "    print(('Features: ', X_train_dtm.shape[1]))\n",
    "    X_test_dtm = vect.transform(X_test)\n",
    "    svc = SVC()\n",
    "    svc.fit(X_train_dtm, y_train)\n",
    "    y_pred_class = svc.predict(X_test_dtm)\n",
    "    #print(('Accuracy: ', metrics.accuracy_score(y_test, y_pred_class)))\n",
    "    print(metrics.classification_report(y_test, y_pred_class))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "vect = CountVectorizer(max_df=.75, ngram_range=(1, 2), stop_words=\"english\", min_df=2)\n",
    "tokenize_test_svc(vect)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
